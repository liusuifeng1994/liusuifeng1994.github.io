<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Liusuifeng&#39;s Blog">
<meta property="og:url" content="https://liusuifeng1994.github.io/index.html">
<meta property="og:site_name" content="Liusuifeng&#39;s Blog">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Liusuifeng&#39;s Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://liusuifeng1994.github.io/">





  <title>Liusuifeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liusuifeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka客户端深入/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka客户端深入/" itemprop="url">kafka客户端深入</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-17T13:00:00+08:00">
                2020-03-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kafka客户端深入"><a href="#kafka客户端深入" class="headerlink" title="kafka客户端深入"></a>kafka客户端深入</h1><h2 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h2><p>Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略</p>
<h3 id="RangeAssignor分配策略"><a href="#RangeAssignor分配策略" class="headerlink" title="RangeAssignor分配策略"></a>RangeAssignor分配策略</h3><p>RangeAssignor分配策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区</p>
<p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区<br>假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有4个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t0p3、t1p0、t1p1、t1p2、t1p3。最终的分配结果为：<br>消费者C0：t0p0、t0p1、t1p0、t1p1<br>消费者C1：t0p2、t0p3、t1p2、t1p3</p>
<p>假设2个主题都只有3个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：<br>消费者C0：t0p0、t0p1、t1p0、t1p1<br>消费者C1：t0p2、t1p2</p>
<h3 id="RoundRobinAssignor分配策略"><a href="#RoundRobinAssignor分配策略" class="headerlink" title="RoundRobinAssignor分配策略"></a>RoundRobinAssignor分配策略</h3><p>RoundRobinAssignor分配策略的原理是将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区一次分配给每个向消费者。RoundRobinAssignor分配策略对应的partition.assignment.strategy参数值为org.apache.kafka.clients.consumer.RoundRobinAssignor</p>
<p>如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor分配策略的分区分配会是均匀的</p>
<p>假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么订阅的所有分区可以表示为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终分配结果为：<br>消费者C0：t0p0、t0p2、t1p1<br>消费者C1：t0p1、t1p0、t1p2</p>
<p>如果同一个消费组内的消费者订阅的信息不是相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能导致分区分配得不均匀<br>假设消费组内有3个消费者（C0、C1和C2），它们共订阅了3个主题（t0、t1和t2），这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区，消费者C0订阅了主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果是：<br>消费者C0：t0p0<br>消费者C1：t1p0<br>消费者C2：t1p1、t2p0、t2p1、t2p2</p>
<h3 id="StickyAssignor分配策略"><a href="#StickyAssignor分配策略" class="headerlink" title="StickyAssignor分配策略"></a>StickyAssignor分配策略</h3><p>引入这个策略主要有两个目的：<br>    分区的分配要尽可能均匀<br>    分区的分配尽可能与上次分配的保持相同<br>当两者发生冲突时，第一个目标优先于第二个目标</p>
<p>假设消费组内有3个消费者（C0、C1和C2），它们都订阅了4个主题（t0、t1、t2、t3），并且每个主题有2个分区。也就是说，整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下：<br>消费者C0：t0p0、t1p1、t3p0<br>消费者C1：t0p1、t2p0、t3p1<br>消费者C2：t1p0、t2p1</p>
<p>和RoundRobinAssignor分配策略所分配的结果相同，假设此时消费者C1脱离了消费组，那么消费组就会执行再均衡操作， 进而消费分区会重新分配。如果采用RoundRobinAssignor分配策略，那么此时的分配结果如下：<br>消费者C0：t0p0、t1p0、t2p0、t3p0<br>消费者C2：t0p1、t1p1、t2p1、t3p1</p>
<p>RoundRobinAssignor分配策略会按照消费者C0和C2进行重新轮询分配。如果使用的是StickyAssignor分配策略，分配结果为：<br>消费者C0：t0p0、t1p1、t3p0、t2p0<br>消费者C2：t1p0、t2p1、t0p1、t3p1</p>
<p>分配结果中保留了上一次分配中对消费者C0和C2的所有分配结果，并将原来消费者C1的负担分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡</p>
<p>StickyAssignor分配策略尽可能地让前后两次分配相同，进而减少系统资源的损耗及其他异常情况的发生<br>假设消费组内有3个消费者（C0、C1和C2），它们共订阅了3个主题（t0、t1和t2），这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区，消费者C0订阅了主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果是<br>消费者C0：t0p0<br>消费者C1：t1p0、t1p1<br>消费者C2：t2p0、t2p1、t2p2</p>
<h3 id="自定义分区分配策略"><a href="#自定义分区分配策略" class="headerlink" title="自定义分区分配策略"></a>自定义分区分配策略</h3><p>自定义的分配策略必须要实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口</p>
<p>PartitionAssignor接口中定义了两个内部类：Subscription和Assignment<br>Subscription类用来表示消费者的订阅信息，类中有两个属性：topics和userData，分别表示消费者的订阅主题列表和用户自定义信息<br>Assignment类用来表示分配结果信息，类中也有两个属性：partitions和userData，分别表示所分配到的分区集合和用户自定义的数据<br>onAssignment()方法是在每个消费者收到消费组leader分配结果时的回调函数<br>name()方法用来提供分配策略的名称，自定义的分配策略要注意命名不要与已存在的分配策略发生冲突<br>真正的分区分配方案的实现是在assign()方法中，方法中的参数metadata表示集群的元数据信息，而subscriptions表示消费组内各个消费者成员的订阅信息，最终方法返回各个消费者的分配信息</p>
<h2 id="消费者协调器和组协调器"><a href="#消费者协调器和组协调器" class="headerlink" title="消费者协调器和组协调器"></a>消费者协调器和组协调器</h2><h3 id="再均衡的原理"><a href="#再均衡的原理" class="headerlink" title="再均衡的原理"></a>再均衡的原理</h3><p>消费者客户端将全部消费者组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，GroupCoordinator是Kafka服务端中用于管理消费组的组件。而消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。<br>ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括分区分配的工作也是在再均衡期间完成的</p>
<p>当有消费者加入消费组时，消费者、消费组及组协调器之间会经历一下几个阶段<br><strong>第一阶段（FIND_COORDINATOR）</strong><br>消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接。如果消费者已经保存了与消费组对应的GroupCoordinator节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则，就需要向集群中的负载最小的节点发送FindCoordinatorRequest请求来查找对应的GroupCoordinator</p>
<p>FindCoordinatorRequest请求体中只有两个域：coordinator_key和coordinator_type。coordinator_key是消费组的名称，即groupId，coordinator_type置为0<br><img src="/media/15843273229031.jpg" alt="-w833"></p>
<p>Kafka在收到FindCoordinatorRequest请求之后，会根据coordinator_key查找对应的GroupCoordinator节点，找到对应的GroupCoordinator则会返回其相应的nod_id、host和port信息</p>
<p><strong>第二阶段（JOIN_GROUP）</strong><br>在成功找到消费组所对应的GroupCoordinator之后就进入加入消费组的阶段，在此阶段的消费者会向GroupCoordinator发送JoinGroupRequest请求，并处理响应<br><img src="/media/15843273748546.jpg" alt="-w822"></p>
<p>joinGroupRequest的结构包含多个域：</p>
<ul>
<li>group_id就是消费组的id</li>
<li>session_timeout对应消费端参数session.timeout.ms，默认值为10000，即10秒。GroupCoordinator超过session_timeout指定的时间内没有收到心跳报文则认为此消费者已经下线</li>
<li>rebalance_timeout对应消费端参数max.poll.interval.ms，默认值为300000，即5分钟。表示当下消费组再均衡的时候，GroupCoordinator等待各个消费者重新加入的最长等待时间</li>
<li>member_id表示GroupCoordinator分配给消费者的id标识。消费者第一次发送JoinGroupRequest请求的时候此字段设置为null</li>
<li>protocol_type表示消费组实现的协议，对于此消费者而言此字段值为consumer</li>
</ul>
<p>JoinGroupRequest中的group_protocols域为数组类型，其中可以囊括多个分区分配策略，主要取决于消费者客户端参数partition.assignment.strategy的配置。如果配置了多种策略，那么JoinGroupRequest中就会包含多个protocol_name和protocol_metadata</p>
<p>消费者在发送JoinGroupRequest请求之后会阻塞等待Kafka服务端的响应。服务端在收到JoinGroupRequest请求后会交由GroupCoordinator来进行处理。GroupCoordinator首先会对JoinGroupRequest请求做合法性校验。如果消费者是第一次请求加入消费组，那么JoinGroupRequest请求中的member_id值为null，此时组协调器负责为此消费者生成一个member_id（clientId+”-“+UUID）</p>
<p>1）选举消费组的leader<br>GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader。如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader。如果某一时刻leader消费者退出了消费组，那么会重新选举一个新的leader。在GroupCoordinator中消费者的信息是以HashMap的形式存储的，其中key为消费者的member_id，而value是消费者相关的元数据信息。leaderId表示leader消费者的member_id，它的取值为HashMap中的第一个键值对的key</p>
<p>2）选举分区分配策略<br>分区分配的选举并非由leader消费者决定，而是根据消费组内的各个消费者投票来决定<br>A.收集各个消费者支持的所有分配策略，组成候选集candidates<br>B.每个消费者从候选集candidates中找出第一个自身支持的策略，为这个策略投上一票<br>C.计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略</p>
<p>消费者所支持的分配策略是partition.assignment.strategy参数配置的策略<br>在此之后，Kafka服务端就要发送JoinGroupResponse响应给各个消费者，JoinGroupResponse中包含GroupCoordinator中投票选举出的分配策略的信息。并且，只有leader消费者的JoinGroupResponse中包含各个消费者的订阅信息。Kafka把分区策略的具体分配交还给客户端，自身并不参与具体的分配细节，这样即使以后分区分配的策略发生了变更，只需要重启消费端的应用即可，而不需要重启服务端</p>
<p><img src="/media/15843277236078.jpg" alt="-w469"></p>
<p><img src="/media/15843277377271.jpg" alt="-w453"></p>
<p><strong>第三阶段（SYNC_GROUP）</strong><br>在第三个阶段，也就是同步阶段，各个消费者GroupCoordinator发送SyncGroupRequest请求来同步分配方案<br><img src="/media/15843278063361.jpg" alt="-w469"></p>
<p>GroupCoordinator会先对SyncGroupRequest请求做合法性校验，在此之后会将从leader消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送SyncGroupResponse给各个消费者各自所属的分配方案</p>
<p>当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment()方法。随后再调用ConsumerRebalanceListener中的onPartitionsAssigned()方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartBeatRequest来确定彼此在线</p>
<p><strong>第四阶段（HEARTBEAT）</strong><br>消费组中的所有消费者处于正常工作状态。在正式消费之前，消费者还需要确定拉取消息的起始位置。假设之前已经将最后的消费位移提交到了GroupCoordinator，并且GroupCoordinator将其保存到了Kafka内部的__consumer_offsets主题中，此时消费者可以通过OffsetFetchRequest请求获取上次提交的消费位移并从此处继续消费</p>
<p>消费者通过向GroupCoordinator发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区中的消息。心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话被判定为过期，GroupCoordinator也会认为这个消费者已经死亡，就会触发一次再均衡行为</p>
<h2 id="事务与幂等"><a href="#事务与幂等" class="headerlink" title="事务与幂等"></a>事务与幂等</h2><h3 id="消息传输保障"><a href="#消息传输保障" class="headerlink" title="消息传输保障"></a>消息传输保障</h3><p>消息中间件的消息传输保障有3个层级：</p>
<ul>
<li>at most once：至多一次。消息可能会丢失，但绝对不会重复传输</li>
<li>at least once：最少一次。消息绝不会丢失，但可能会重复传输</li>
<li>exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次</li>
</ul>
<h3 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h3><p>幂等是指对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka的幂等性功能之后就可以避免这种情况</p>
<p>开启幂等性功能需要显示地将生产者客户端参数enable.idempotence设置为true即可（这个参数默认值为false）<br><code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);</code></p>
<p>如果要确保幂等性功能正常，需要确保生产者客户端的retries、acks、max.in.flight.requests.per.connection这几个参数不被配置错。在使用幂等性功能的时候，用户完全不需要配置这几个参数</p>
<p>如果用户显示指定了retries参数，那么这个参数的值必须大于0，如果没有显示指定retries参数，那么KafkaProducer会将它置为Integer.MAX_VALUE。同时还要保证max.in.flight.requests.per.connection（限制每个连接最多缓存的请求数）参数的值不能大于5，acks参数的值为-1</p>
<p>为了实现生产者的幂等性，Kafka为此引入了producer id（PID）和序列号这两个概念。每个新的生产者实例在初始化的时候都会被分配一个PID，这个PID对用户而言是完全透明的。对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将&lt;PID，分区&gt;对应的序列号的值加1</p>
<p>broker端会在内存中为每一对&lt;PID，分区&gt;维护一个序列号。对于收到的每一条消息，只有当它的序列号的值比broker端中维护的对应的序列号的值大1（即SN_new=SN_old+1）时，broker才会接收它。如果SN_new&lt;SN_old+1，那么说明消息被重复写入，broker可以直接将其丢弃。如果SN_new&gt;SN_old+1，那么说明中间有数据尚未写入，出现了乱序，可能有消息丢失，对应的生产者会抛出OutOfOrderSequenceException</p>
<p>引入序列号来实现幂等性只是针对每一对&lt;PID，分区&gt;而言的，也就是说，Kafka的幂等性只能保证单个生产者会话中单分区的幂等</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务可以保证对多个分区写入操作的原子性。Kafka中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败，即使该生产或消费会跨多个分区</p>
<p>为了实现事务，应用程序必须提供唯一的transactionId，这个transactionId通过客户端参数transactional.id来显示指定<br><code>props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;transactionId&quot;);</code></p>
<p>事务要求生产者开启幂等特性，因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将enable.idempotence设置为true（如果未显示指定，则KafkaProducer默认会将它的值设置为true）</p>
<p>transactionId与PID一一对应，两者之间所不同的是transactionId由用户显示指定，而PID是由Kafka内部分配的。另外，为了保证新的生产者启动后具有相同transactionId的旧生产者能够立即失效，每个生产者通过transactionId获取PID的同时，还会获取一个单调递增的producer epoch。如果使用同一个transactionId开启两个生产者，那么前一个开启的生产者会报错</p>
<p>从生产者的角度分析，通过事务，Kafka可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复。前者表示具有相同transactionId的新生产者实例被创建且工作的时候，旧的且拥有相同transactionId的生产者实例将不再工作。后者指当某个生产者实例宕机后，新的生产者实例可以保证任何未完成的旧事物要么被提交，要么被中止，如此可以是新的生产者实例从一个正常的状态开始工作</p>
<p>从消费者的角度分析，Kafka并不能保证已提交的事务中的所有消息都能够被消费：</p>
<ul>
<li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理（相同key的消息，后写入的消息会覆盖前面写入的消息）</li>
<li>事务中消息可能分布在同一个分区的多个日志分段中，当老的日志分段被删除时，对应的消息可能会丢失</li>
<li>消费者可以通过seek()方法访问任意offset的消息，从而可能遗漏事务中的部分消息</li>
<li>消费者在消费时可能没有分配到事务内的所有分区，如此它也就不能读取事务中的所有消息</li>
</ul>
<p>KafkaProducer提供了5个与事务相关的方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//初始化事务</span><br><span class="line">void initTransactions()</span><br><span class="line">//开启事务</span><br><span class="line">void beginTransaction() throws ProducerFencedException</span><br><span class="line">//消费者在事务内的位移提交</span><br><span class="line">void sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span><br><span class="line">							  String consumerGroupId) throws ProducerFencedException</span><br><span class="line">//提交事务							  </span><br><span class="line">void commitTransaction() throws ProducerFencedException</span><br><span class="line">//中止事务</span><br><span class="line">void abortTransaction() throws ProducerFencedException</span><br></pre></td></tr></table></figure>
<p>事务发送事例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, transactionId);</span><br><span class="line">KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">producer.initTransactions();</span><br><span class="line">producer.beginTransaction();</span><br><span class="line">try &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record1 = new ProducerRecord&lt;&gt;(topic, &quot;msg1&quot;);</span><br><span class="line">    producer.send(record1);</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record2 = new ProducerRecord&lt;&gt;(topic, &quot;msg2&quot;);</span><br><span class="line">    producer.send(record2);</span><br><span class="line">    producer.commitTransaction();</span><br><span class="line">&#125; catch (ProducerFencedException e) &#123;</span><br><span class="line">    producer.abortTransaction();</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">    producer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在消费端有一个参数isolation.level，默认值为read_uncommitted，意思是说消费端应用可以消费到未提交的事务。还可以设置为read_committed，表示消费端应用只能看到提交的事务<br><img src="/media/15843282888371.jpg" alt="-w660"><br>日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是控制消息（ControlBatch）。控制消息一共有两种类型：COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止。KafkaConsumer可以通过这个控制消息来判断对应的事务是被提交了还是被中止了，然后结合参数isolation.level配置的隔离级别来决定是否将相应的消息返回给消费端应用</p>
<p>consume-transform-produce（消费-转换-生产）示例：<br><img src="/media/15843283068631.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest</span><br><span class="line">public class TransactionConsumerTransformProduceTest &#123;</span><br><span class="line">    public static final String brokerList = &quot;192.168.126.158:9092&quot;;</span><br><span class="line"></span><br><span class="line">    public Properties getConsumerProperties() &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;groupId&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Properties getProducerProperties() &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;transactionId&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    public void consumerTransformProduceTest() &#123;</span><br><span class="line">        //初始化生产者和消费者</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(getConsumerProperties());</span><br><span class="line">        consumer.subscribe(Collections.singleton(&quot;topic-source&quot;));</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(getProducerProperties());</span><br><span class="line">        //初始化事务</span><br><span class="line">        producer.initTransactions();</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000));</span><br><span class="line">            if (!records.isEmpty()) &#123;</span><br><span class="line">                Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();</span><br><span class="line">                //开启事务</span><br><span class="line">                producer.beginTransaction();</span><br><span class="line">                try &#123;</span><br><span class="line">                    for (TopicPartition partition : records.partitions()) &#123;</span><br><span class="line">                        List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);</span><br><span class="line">                        for (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123;</span><br><span class="line">                            System.out.println(&quot;topic=&quot; + record.topic() + &quot;,partition=&quot; + record.partition() + &quot;,offset=&quot; + record.offset());</span><br><span class="line">                            System.out.println(&quot;key=&quot; + record.key() + &quot;,value=&quot; + record.value());</span><br><span class="line">                            ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;&gt;(&quot;topic-sink&quot;, record.key(), record.value());</span><br><span class="line">                            //消费-生产模型</span><br><span class="line">                            producer.send(producerRecord);</span><br><span class="line">                        &#125;</span><br><span class="line">                        long lastConsumedOffset = partitionRecords.get(partitionRecords.size() - 1).offset();</span><br><span class="line">                        offsets.put(partition, new OffsetAndMetadata(lastConsumedOffset + 1));</span><br><span class="line">                    &#125;</span><br><span class="line">                    //提交消费位移</span><br><span class="line">                    producer.sendOffsetsToTransaction(offsets, &quot;groupId&quot;);</span><br><span class="line">                    //提交事务</span><br><span class="line">                    producer.commitTransaction();</span><br><span class="line">                &#125; catch (ProducerFencedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                    producer.abortTransaction();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了实现事务的功能，Kafka引入了事务协调器（TransactionCoordinator）。每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括分派PID等都是由TransactionCoordinator来负责实施的。TransactionCoordinator会将事务状态持久化到内部主题__transaction_state中</p>
<p>以consume-transform-produce的流程为例分析Kafka事务的实现原理<br><img src="/media/15843283944359.jpg" alt="-w763"></p>
<h4 id="1）查找TransactionCoordinator"><a href="#1）查找TransactionCoordinator" class="headerlink" title="1）查找TransactionCoordinator"></a>1）查找TransactionCoordinator</h4><p>生产者向Kafka发送FindCoordinatorRequest请求，Kafka在收到FindCoordinatorRequest请求之后，会根据coordinator_key（transactionId）查找对应的TransactionCoordinator节点。如果找到，则会返回其相应的node_id、host和port信息。具体查找TransactionCoordinator的方式是根据transactionId的哈希值计算主题__transaction_state中的分区编号，找到对应的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为transactionId对应的TransactionCoordinator节点</p>
<h4 id="获取PID"><a href="#获取PID" class="headerlink" title="获取PID"></a>获取PID</h4><p><img src="/media/15843284515676.jpg" alt=""><br>在找到TransactionCoordinator节点之后，需要为当前生产者分配一个PID。凡是开启了幂等性功能的生产者都必须执行这个操作，不需要考虑该生产者是否还开启了事务。生产者获取PID的操作是通过InitProducerIdRequest请求来实现的，InitProducerIdRequest请求体结构如上图所示，其中transactional_id表示事务的transactionId，transaction_timeout_ms表示TransactionCoordinator等待事务状态更新的超时时间，通过生产者客户端参数transaction.timeout.ms配置，默认值为60000<br><img src="/media/15843284983945.jpg" alt="-w592"></p>
<p>生产者的InitProducerIdRequest请求会被发送给TransactionCoordinator。如果没开启事务特性而只开启幂等特性，那么InitProducerIdRequest请求可以发送给任意的broker。当TransactionCoordinator第一次收到包含该transactionId的InitProducerIdRequest请求时，它会把transactionId和对应的PID以消息（事务日志消息）的形式保存到主题__transaction_state中，如上图所示。这样可以保证&lt;transactionId,PID&gt;的对应关系被持久化，从而保证即使TransactionCoordinator宕机该对应关系也不会丢失</p>
<p>其中transaction_status包含Empty(0)、Ongoing（1）、PrepareCommit(2)、PrepareAbort(3)、CompleteCommit(4)、CompleteAbort(5)、Dead(6)这几种状态。在存入主题__transaction_state之前，事务日志消息同样会根据单独的transactionId来计算要发送的分区<br><img src="/media/15843285202365.jpg" alt=""></p>
<p>initProducerIdRequest对应的InitProducerIdResponse响应体结构如上图所示，除了返回PID，还会触发执行以下任务：</p>
<ul>
<li>增加该PID对应的producer_epoch。具有相同PID但producer_epoch小于该producer_epoch的其他生产者新开启的事务将被拒绝</li>
<li>恢复和终止之前的生产者未完成的事务</li>
</ul>
<h4 id="3）开启事务"><a href="#3）开启事务" class="headerlink" title="3）开启事务"></a>3）开启事务</h4><p>通过KafkaProducer的beginTransaction()方法可以开启一个事务，调用该方法后，生产者本地会标记已经开启一个新的事务，只有在生产者发送第一条消息之后TransactionCoordinator才会认为该事务已经开启</p>
<h4 id="4）Consume-Transform-Produce"><a href="#4）Consume-Transform-Produce" class="headerlink" title="4）Consume-Transform-Produce"></a>4）Consume-Transform-Produce</h4><p>这个阶段囊括了整个事务的数据处理过程</p>
<p><strong>AddPartitionsToTxnRequest</strong><br>当生产者给一个新的分区（TopicPartition）发送数据前，它需要先向TransactionCoordinator发送AddPartitionsToTxnRequest请求，这个请求会让TransactionCoordinator将&lt;transactionId,TopicPartition&gt;的对应关系存储在主题__transaction_state中，有了这个对照关系在后续的步骤中为每个分区设置COMMIT或ABORT标记<br>如果该分区是对应事务中的第一个分区，那么此时TransactionCoordinator还会启动对该事务的计时</p>
<p><strong>ProduceRequest</strong><br>生产者通过ProduceRequest请求发送消息（ProducerBatch）到用户自定义主题中，和普通消息不同的是ProducerBatch中会包含实质的PID、producer_epoch和sequence number</p>
<p><strong>AddOffsetsToTxnRequest</strong><br>通过KafkaProducer的sendOffsetsToTransaction()方法可以在一个事务批次里处理消息的消费和发送，方法中包含2个参数：Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets和String consumerGroupId。这个方法会向TransactionCoordinator节点发送AddOffsetsToTxnRequest请求。TransactionCoordinator收到这个请求之后会通过groupId来推导出在<strong>consumer_offsets中的分区，之后TransactionCoordinator会将整个分区保存在</strong>transaction_state中</p>
<p><strong>TxnOffsetCommitRequest</strong><br>这个请求也是sendOffsetsToTransaction()方法中的一部分，在处理完AddOffsetsToTxnRequest之后，生产者还会发送TxnOffsetCommitRequest请求给GroupCoordinator，从而将本次事务中包含的消费位移信息offsets存储到主题__consumer_offsets中</p>
<h4 id="5）提交或者中止事务"><a href="#5）提交或者中止事务" class="headerlink" title="5）提交或者中止事务"></a>5）提交或者中止事务</h4><p><strong>EndTxnRequest</strong><br>无论调用commitTransaction()方法还是abortTransaction()方法，生产者都会向TransactionCoordinator发送EndTxnRequest请求，以此来通知它提交事务还是中止事务<br>TransactionCoordinator在收到EndTxnRequest请求之后会执行如下操作：</p>
<ul>
<li>A.将PREPARE_COMMIT或PREPARE_ABORT消息写入主题__transaction_state</li>
<li>B.通过WriteTxnMarkersRequest请求将COMMIT或ABORT信息写入用户所使用的普通主题和__consumer_offsets</li>
<li>C.将COMPLETE_COMMIT或COMPLETE_ABORT信息写入内部主题__transaction_state</li>
</ul>
<p><strong>WriteTxnMarkersRequest</strong><br>WriteTxnMarkersRequest请求是由TransactionCoordinator发向事务中各个分区的leader节点的，当节点收到这个请求之后，会在相应的分区中写入控制消息（ControlBatch）。控制消息用来标识事务的终结，它和普通的消息一样存储在日志文件中。RecordBatch中attributes字段的第6位用来标识当前消息是否是控制消息<br><img src="/media/15843286447750.jpg" alt=""><br>attributes字段中的第5位用来标识当前消息是否处于事务中<br><img src="/media/15843287094227.jpg" alt=""><br>控制消息的key和value内部的version值都为0，key中的type表示控制类型：0表示ABORT，1表示COMMIT；value中的coordinator_epoch表示TransactionCoordinator的纪元，TransactionCoordinator切换的时候会更新其值</p>
<p><strong>写入最终的COMPLETE_COMMIT或COMPLETE_ABORT</strong><br>TransactionCoordinator将最终的COMPLETE_COMMIT或COMPLETE_ABORT信息写入主题<strong>transaction_state以表明当前事务已经结束，此时可以删除主题</strong>transaction_state中所有关于该事务的消息。由于主题__transaction_state采用的日志清理策略为日志压缩，所以这里的删除只需要将相应的消息设置为墓碑消息即可</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka可靠性探究/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka可靠性探究/" itemprop="url">kafka可靠性探究</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T13:00:00+08:00">
                2020-03-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kafka可靠性探究"><a href="#kafka可靠性探究" class="headerlink" title="kafka可靠性探究"></a>kafka可靠性探究</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka应用/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka应用/" itemprop="url">kafka应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T13:00:00+08:00">
                2020-03-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kafka应用"><a href="#kafka应用" class="headerlink" title="kafka应用"></a>kafka应用</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka监控/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka监控/" itemprop="url">kafka监控</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T13:00:00+08:00">
                2020-03-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kafka监控"><a href="#kafka监控" class="headerlink" title="kafka监控"></a>kafka监控</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka服务端深入/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka服务端深入/" itemprop="url">kafka服务端深入</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T13:00:00+08:00">
                2020-03-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="kafka服务端深入"><a href="#kafka服务端深入" class="headerlink" title="kafka服务端深入"></a>kafka服务端深入</h1><h2 id="协议设计"><a href="#协议设计" class="headerlink" title="协议设计"></a>协议设计</h2><p>Kafka自定义了一组基于TCP的二进制协议，只要遵守这组协议的格式，就可以向Kafka发送消息，也可以从中拉取消息。在Kafka2.0.0中，一共包含了43种协议类型，每种协议类型都有对应的请求和响应，它们都遵循特定的协议模式。每种类型的Rquest都包含相同结构的协议请求头和不同结构的协议请求体<br><img src="/media/15843253500633.jpg" alt=""></p>
<p>协议请求头中包含4个域：api_key、api_version、correlation_id和client_id<br><img src="/media/15843253727598.jpg" alt=""><br>每种类型的Response也包含相同结构的协议响应头和不同结构的响应体<br><img src="/media/15843254014287.jpg" alt=""><br>协议响应头中只有一个correlation_id</p>
<h2 id="时间轮"><a href="#时间轮" class="headerlink" title="时间轮"></a>时间轮</h2><p>Kafka的延时操作是基于时间轮的概念自定义实现了一个用于延时功能的定时器。JDK中Timer和DelayQueue的插入和删除操作的平均时间复杂度为O(nlogn)，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)<br>Kafka中的时间轮是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素都可以存放一个定时任务列表（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项，其中封装了真正的定时任务</p>
<p>时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度（tickMs）。时间轮的时间格个数是固定的，可用wheelSize来表示，那么整个时间轮的总体时间跨度（interval）可以通过公式tickMs*wheelSize计算得出。时间轮还有一个表盘指针（currentTime），用来表示时间轮当前所处的时间，currentTime是tickMs的整数倍。currentTime可以将整个时间轮划分为到期部分和未到期部分，currentTime当前指向的时间格也属于到期部分，表示刚到到期，需要处理此时间格所对应的TimerTaskList中的所有任务<br><img src="/media/15843256512136.jpg" alt="-w680"><br>若时间轮的tickMs为1ms且wheelSize等于20，可以计算得出总体时间跨度interval为20ms。初始情况下表盘指针currentTime指向时间格0，此时有一个定时为2ms的任务插进来会存放到时间格为2的TimerTaskList中。随着时间推移，指针currentTime不断向前推进，过了2ms之后，当到达时间格2时，就需要将时间格2对应的TimerTaskList中的任务进行相应的到期操作。此时若有一个定时为8ms的任务插进来，则会存放到时间格10中，currentTime再过8ms后会指向时间格10.如果同时有一个定时为19ms的任务插进来，新来的TimerTaskEntry会复用原来的TimerTaskList，所以它会插入原本已经到期的时间格1。整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间</p>
<p>Kafka引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中<br><img src="/media/15843257633814.jpg" alt="-w754"></p>
<p>上图中，第一层的时间轮tickMs=1ms、wheelSize=20、interval=20ms。第二层的时间轮的tickMs为第一层时间轮的interval，即20ms。每一层时间轮的wheelSize是固定的，都是20，那么第二层的时间轮的总体时间跨度interval为400ms。这个400ms也是第三层的tickMs的大小，第三层的时间轮的总体时间跨度为8000ms</p>
<p>450ms的定时任务第一层时间轮不能满足条件，所以就升级到第二层时间轮中，第二层时间轮也无法满足条件，所以又升级到第三层时间轮中，最终被插入第三层时间轮中时间格1所对应的TimerTaskList。在到期时间为[400ms,800ms)区间内的多个任务都会被放入第三层时间轮的时间格1，时间格1对应的TimerTaskList的超时时间为400ms。随着时间的推移，当此TimerTaskList到期之时，原本定时为450ms的任务还剩下50ms的时间，还不能执行这个任务的到期操作。这时候会做一个时间轮降级的操作，会将整个剩余时间为50ms的定时任务重新提交到层级时间轮中，此时第一层时间轮的总体时间跨度不够，而第二层足够，所以该任务被放到第二层时间轮到期时间为[40ms,60ms)的时间格中。再经历40ms之后，此时这个任务还剩10ms，还是不能立即执行到期操作。所以还要再有一次时间轮的降级，此任务被添加到第一层时间轮到期时间为[10ms,11ms)的时间格中，之后再经历10ms后，此任务真正到期，最终执行相应的到期操作</p>
<ul>
<li>时间轮在创建的时候以当前系统时间为第一层时间轮的起始时间</li>
<li>时间轮中的每个双向环形链表TimerTaskList都会有一个哨兵节点，作为第一个节点，它的值域不存储任何东西，只是为了操作的方便而引入的</li>
<li>除了第一层时间轮，其余高层时间轮的起始时间都设置为创建此层时间轮前面第一轮的currentTime。第一层的currentTime都必须是tickMs的整数倍</li>
<li>Kafka中的定时器只需持有时间轮的第一层时间轮的引用，并不会直接持有其他高层的时间轮，但每一层时间轮都会有一个引用指向更高一层的应用，以此层级调用可以实现定时器间接持有各个层级时间轮的引用</li>
</ul>
<p>Kafka中的定时器借用了JDK中的DelayQueue来协助推进时间轮。对于每个使用到的TimerTaskList（费哨兵节点的定时任务项TimerTaskEntry对应的TimerTaskList）都加入DelayQueue。DelayQueue会根据TimerTaskList对应的超时时间expiration来排序，最短expiration的TimerTaskList会被排在DelayQueue的队头。Kafka中会有一个线程（ExpiredOperationReaper）来获取DelayQueue中到期的任务列表。当线程获取DelayQueue中超时的任务列表TimerTaskList之后，即可以根据TimerTaskList的expiration来推进时间轮的时间，也可以就获取的TimerTaskList执行相应的操作，对里面的TimerTaskEntry该执行过期操作的就执行过期操作，该降级时间轮的就降级时间轮</p>
<p>Kafka中的时间轮专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务</p>
<p>DelayQueue中第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度（获取之后DelayQueue内部才会再次切换出新的队头）。如果采用每秒定时推进，那么获取第一个超时的任务列表时执行的200次推进中有199次属于空推进，而获取第二个超时任务时有需要执行639次空推进，这样会无故空耗机器的性能资源</p>
<h2 id="延时操作"><a href="#延时操作" class="headerlink" title="延时操作"></a>延时操作</h2><h3 id="延时生产"><a href="#延时生产" class="headerlink" title="延时生产"></a>延时生产</h3><p>如果在使用生产者客户单发送消息的时候将acks参数设置为-1，那么就意味着需要等待ISR集合中的所有副本都确认收到消息之后才能正确地收到响应的结果，或者捕获超时异常。在将消息写入leader副本的本地日志文件之后，Kafka会创建一个延时的生产操作，用来处理消息正常写入所有副本或超时的情况，以返回相应的响应结果给客户端</p>
<p>随着follower副本不断地与leader副本进行消息同步，进而促使HW进一步增长，HW每增长一次都会检测是否能够完成此次延时生产操作，如果可以就执行以此返回响应结果给客户端；如果在超时时间内始终无法完成，则强制执行</p>
<p>延时操作创建之后会被加入延时操作管理器来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器来做超时管理，定时器的底层就是采用时间轮实现的。时间轮的轮转是靠线程ExpiredOperationReaper来驱动的，这里ExpiredOperationReaper由延时操作管理器启动的。定时器、ExpiredOperationReaper和延时操作管理器都是一一对应的。延时操作需要支持外部事件的触发，所以还要配备一个监听池来负责监听每个分区的外部事件——查看是否有分区的HW发生了增长。ExpiredOperationReaper不仅可以推进时间轮，还会定期清理监听池中已完成的延时操作<br><img src="/media/15843259687986.jpg" alt="-w731"></p>
<p>如果客户端设置的acks参数不为-1，或者没有成功的消息写入，那么就直接返回结果给客户端，否则就需要创建延时生产操作并存入延时操作管理器，最终要么由外部事件触发，要么超时触发而执行</p>
<h3 id="延时拉取"><a href="#延时拉取" class="headerlink" title="延时拉取"></a>延时拉取</h3><p>两个follower副本都已经拉取到了leader副本的最新位置，此时又向leader副本发送拉取请求，而leader副本没有新的消息写入，这时Kafka选择了延时操作来处理这种情况。Kafka在处理拉取请求时，会先去读一次日志文件，如果收集不到足够多（fetchMinBytes，由参数fetch.min.bytes配置，默认值为1）的的消息，那么就会创建一个延时拉取操作以等待拉取到足够数量的消息。当延时拉取操作执行时，会再读取一次日志文件，然后将拉取结果返回给follower副本。延时拉取操作也会有一个专门的延时操作管理器负责管理，大体和延时生产相同。如果拉取进度一直没有追赶上leader副本，那么在拉取leader副本的消息时一般拉取的消息大小都会不小于fetchMinBytes，这样Kafka也就不会创建相应的延时拉取操作，而是立即返回拉取结果</p>
<h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><p>在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器( Kafka Controller)，它负责管理整个集群中所有分区和副本的状态。当某个分区的 leader 副本出现故 障时，由控制器负责为该分区选举新的 leader副本。当检测到某个分区的 ISR集合发生变化时， 由控制器负责通知所有 broker更新其元数据信息。当使用 kafka-topics.sh 脚本为某个 topic 增加分区数量时，同样还是由控制器负责分区的重新分配 。</p>
<h3 id="控制器的选举及异常恢复"><a href="#控制器的选举及异常恢复" class="headerlink" title="控制器的选举及异常恢复"></a>控制器的选举及异常恢复</h3><p>Kafka中的控制器选举工作依赖于ZooKeeper，成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时节点，此临时节点的内容参考如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 0] get /controller</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;brokerid&quot;:1,&quot;timestamp&quot;:&quot;1558621064185&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中version在目前版本中固定为1，brokerid表示成为控制器的broker的id编号，timestamp表示竞选成为控制器时的时间戳</p>
<p>在任意时刻，集群中有且仅有一个控制器。每个broker启动的时候会去尝试读取/controller节点的brokerid的值，如果读取到brokerid的值不为-1，则表示已经有其他broker节点成功竞选为控制器，所以当前broker就会放弃竞选；如果ZooKeeper中不存在/controller节点，或者这个节点中的数据异常，那么就会尝试去创建/controller节点。当前broker去创建节点的时候，也有可能其他broker同时去尝试创建这个节点，只有创建成功的那个broker才会成为控制器，而创建失败的broker竞选失败。每个broker都会在内存中保存当前控制器的brokerid值，这个值可以标记为activeControllerId</p>
<p>ZooKeeper中还有一个与控制器有关的/controller_epoch节点，这个节点是持久节点，节点中存放的是一个整型的controller_epoch值。controller_epoch用于记录控制器发生变更的次数，即记录当前的控制器是第几代控制器，可以称为控制器的纪元</p>
<p>controller_epoch的初始值为1，当控制器发生变更时，每选出一个新的控制器就将该字段值加1。每个和控制器交互的请求都会携带controller_epoch这个字段，如果请求的controller_epoch值小于内存中的controller_epoch值，则认为这个请求是向已经过期的控制器所发送的请求，被认定为无效请求。如果请求的controller_epoch值大于内存的controller_epoch值，那么说明已经有新的控制器当选了。Kafka通过controller_epoch来保证控制器的唯一性</p>
<p><img src="/media/15843261766853.jpg" alt="-w631"></p>
<p>控制器在选举成功之后会读取ZooKeeper中各个节点的数据来初始化上下文信息（ControllerContext），并且需要管理这些上下文信息。不管是监听器触发的事件，还是定时任务触发的事件，或者是其他事件都会读取或更新控制器中的上下文信息，那么就会涉及多线程间的同步。针对这一现象，Kafka的控制器使用单线程基于事件队列的模型，将每个事件都做一层封装，然后按照事件飞升的先后顺序暂存到LinkedBlockingQueue中，最后使用一个专用的线程（ControllerEventThread）按照FIFO的原则顺序处理各个事件，这样不需要锁机制就可以在多线程间维护线程安全</p>
<p>在目前的新版本的设计中，只有Kafka Controller在ZooKeeper上注册相应的监听器，其他的broker极少需要再监听ZooKeeper中的数据变化。不过每个broker还是会对/controller节点添加监听器，以此来监听此节点的数据变化</p>
<p>当/controller节点的数据发生变化时，每个broker都会更新自身内存中保存的activeControllerId。如果broker在数据变更前是控制器，在数据变更后自身的brokerid值与新的activeControllerId值不一致，那么就需要退位，关闭相应的资源，比如关闭状态机、注销相应的监听器等。有可能控制器由于异常而下线，造成/controller这个临时节点被自动删除；也有可能是其他原因将此节点删除了</p>
<p>当/controller节点被删除时，每个broker都会进行选举，如果broker在节点被删除前是控制器，那么在选举前还需要有一个退位的动作。如果有特殊需要，则可以手动删除/controller节点来触发新一轮的选举。当然关闭控制器所对应的broker，以及手动向/controller节点写入新的brokerid的所对应的数据，同样可以触发新一轮选举</p>
<p>具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下:</p>
<ul>
<li>监听分区相关的变化。为 ZooKeeper 中的/admin/reassign partitions节点注册 PartitionReassignmentHandler，用来处理分区重分配的动作。为ZooKeeper中的 /Isr_change_notification 节点注册 IsrChangeNotificetionHandler，用来处理 ISR 集合变更的动作. 为ZooKeeper中的/admin/preferred-replica-election节 点添加 PreferredReplicaElectionHandler，用来处理优先副本的选举动作。</li>
<li>监听主题相关的变化 。为 ZooKeeper 中的 /brokers/topics 节点添加 TopicChangeHandle， 用来处理主题增减变化: 为ZooKeeper 中的/admin/delete topics 节点添加 TopicDeletionHandler，用来处理删除主题的动作。</li>
<li>监听broker相关的变化。为ZooKeeper中的/brokers/ids节点添加 BrokerChangeHandler, 用来处理broker增减的变化。</li>
<li>从ZooKeeper中读取获取当前所有与主题、分区及broker有关的信息并进行相应的管理。 对所有主题对应的ZooKeeper中的 /brokers/topics/<topic>节点添加 PartitionModificationsHandler， 用来监听主题中的分区分配变化 。</topic></li>
<li>启动并管理分区状态机和副本状态机。</li>
<li>更新集群的元数据信息 。</li>
<li>如果参数 auto.leader.rebalance.enable 设置为 true，则还会开启一个名为 “auto-leader-rebalance-task” 的定时任务来负责维护分区的优先副本的均衡。</li>
</ul>
<h3 id="分区leader的选举"><a href="#分区leader的选举" class="headerlink" title="分区leader的选举"></a>分区leader的选举</h3><p>分区leader副本的选举由控制器负责具体实施。当创建分区或分区上线的时候都需要执行leader的选举动作，对应的选举策略为OfflinePartitionLeaderElectionStrategy。这种策略的基本思路是按照AR集合中副本的顺序查找第一个存货的副本，并且这个副本在ISR集合中。一个分区的AR集合在分配的时候就被指定，并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的，而分区的ISR集合中副本的顺序可能会改变</p>
<p>如果ISR集合中没有可用的副本，那么此时还要再检查一下所配置的unclean.leader.election.enable参数（默认值为flase）。如果这个参数配置为true，那么表示允许从非ISR列表中选举leader，从AR列表中找到第一个存活的副本即为leader</p>
<p>当分区进行重分配的时候也需要执行leader的选举动作，对应的选举策略为ReassignPartitionLeaderElectionStrategy。从重分配的AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中</p>
<p>当发生优先副本的选举时，直接将优先副本设置为leader即可，AR集合中的第一个副本即为优先副本</p>
<p>当某节点被优雅地关闭，位于这个节点的leader副本都会下线，需要执行leader的选举。选举策略：从AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中，与此同时还要确保这个副本部委于正在被关闭的节点上</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kakfa日志存储/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kakfa日志存储/" itemprop="url">kafka日志存储</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-15T13:00:00+08:00">
                2020-03-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kafka日志存储"><a href="#Kafka日志存储" class="headerlink" title="Kafka日志存储"></a>Kafka日志存储</h1><h2 id="文件目录布局"><a href="#文件目录布局" class="headerlink" title="文件目录布局"></a>文件目录布局</h2><p>Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后修改。每个消息在发送的时候会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量</p>
<p><img src="/media/15842482454518.jpg" alt="-w566"></p>
<p>为了防止Log过大，Kafka引入了日志分段的概念，将Log切分为多个LogSegment。Log和LogSegment不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，而每个LogSegment对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件</p>
<p>Log对应了一个命名形式为<topic>-<partition>的文件夹。向Log中追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入操作，在此之前的所有LogSegment都不能写入数据。将最后一个LogSegment称为activeSegment，即表示当前活跃的日志分段。随着消息的不断写入，当activeSegment满足一定条件时，就需要创建新的activeSegment，之后追加的消息写入新的activeSegment</partition></topic></p>
<p>为了便于消息的检索，每个LogSegment中的日志文件都有对应的两个索引文件：偏移量索引文件（以.index为文件后缀）和时间戳索引文件（以.timeindex为文件后缀）。每个LogSegment都有一个基准偏移量baseOffset，用来表示当前LogSegment中第一条消息的offset。偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量命名的，名称固定为20位数字，没有达到的位数则用0填充。比如第一个LogSegment的基准偏移量为0，对应的日志文件为00000000000000000000.log</p>
<p>当Kafka服务第一次启动的时候，默认的根目录下就会创建以下5个文件：<br><code>cleaner-offset-checkpoint    log-start-offset-checkpoint    meta.properties               recovery-point-offset-checkpoint    replication-offset-checkpoint</code></p>
<p>消费者提交的位移是保存在Kafka内部的主题__consumer_offsets中的，初始情况下这个主题并不存在，当第一次有消费者消费信息时会自动创建这个主题</p>
<p><img src="/media/15842484397403.jpg" alt="-w682"></p>
<p>每一个根目录都会包含最基本的4个检查点文件（xxx-checkpoint）和meta.properties。在创建主题的时候，如果当前broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务</p>
<h2 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h2><p>从0.8.x版本开始到现在的2.0.0版本， Kafka的消息格式也经历了3个版本: vO版本、 vl版 本和 v2版本。</p>
<h3 id="V0版本"><a href="#V0版本" class="headerlink" title="V0版本"></a>V0版本</h3><p><img src="/media/15842486953742.jpg" alt="-w586"></p>
<p>每个Record（v0和v1版本）必定对应一个offset和message size。每条消息都有一个offset用来标志它在分区中的偏移量，这个offset是逻辑值，message size表示消息的大小，这两者在一起被称为日志头部（LOG_OVERHEAD），固定为12B。LOG_OVERHEAD和RECORD一起用来描述一条消息。消息集中包含一条或多条消息，消息集不仅是存储于磁盘及在网络上传输的基本形式，而且是Kafka中压缩的基本单位</p>
<ul>
<li>crc32（4B）：crc32校验值。校验范围为magic至value之间</li>
<li>magic（1B）：消息格式版本号，此版本的magic值为0</li>
<li>attributes（1B）：消息的属性。总共占1个字节，低3位表示压缩类型：0表示NONE、1表示GZIP、2表示SNAPPY、3表示LZ4，其余位保留</li>
<li>key length（4B）：表示消息的长度。如果为-1，则表示没有设置key</li>
<li>key：可选，如果没有key则无此字段</li>
<li>value length（4B）：实际消息体的长度。如果为-1，则表示消息为空</li>
<li>value：消息体。可以为空，比如墓碑消息</li>
</ul>
<p>v0版本中一个消息的最小长度为crc32+magic+attributes+key length+value length=14B。也就是说，v0版本中一条消息的最小长度为14B，如果小于这个值，那么就是一条破损的消息而不被接收</p>
<h3 id="V1版本"><a href="#V1版本" class="headerlink" title="V1版本"></a>V1版本</h3><p><img src="/media/15842490301193.jpg" alt="-w505"></p>
<p>v1版本比v0版本就多了一个timestamp字段，表示消息的时间戳<br>v1版本的magic字段的值为1。v1版本的attributes字段中的低3位和v0版本的一样，还是表示压缩类型，而第4个为也被利用起来：0表示timestamp类型为CreateTime，而1表示timestamp类型为LogAppendTime，其他位保留。timestamp类型由broker端参数log.message.timestamp.type来配置，默认值为CreateTime，即采用生产者创建消息时的时间戳。如果在创建ProducerRecord时没有显示指定消息的时间戳，那么KafkaProducer也会在发送这条消息前自动添加上</p>
<h3 id="消息压缩"><a href="#消息压缩" class="headerlink" title="消息压缩"></a>消息压缩</h3><p>Kafka实现的压缩方式是将多条消息一起进行压缩。生产者发送到压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩</p>
<p>Kafka日志中使用哪种压缩方式是通过参数compression.type来配置的，默认值为producer，表示保留生产者使用的压缩方式。这个参数还可以设置为gzip、snappy、lz4.如果参数compression.type配置为uncompressed，则表示不压缩<br><img src="/media/15842491423664.jpg" alt="-w533"><br>当消息压缩时是将整个消息集进行压缩作为内层消息，内层消息整体作为外层消息的value<br>压缩后的外层消息中的key为null，value字段中保存的是多条压缩消息，其中Record表示的是从crc32到value的消息格式<br><img src="/media/15842491809480.jpg" alt="-w400"><br>当生产者创建压缩消息的时候，对内部压缩消息设置的offset从0开始为每个内部消息分配offset</p>
<p>其实每个从生产者发出的消息集中的消息offset都是从0开始的，当然这个offset不能直接存储在日志文件中，对offset的转换是在服务端进行的，客户端不需要做这个工作。外层消息保存了内层消息中最后一条消息的绝对位移，绝对位移是相对于整个分区而言的。上图中内层消息中最后一条的offset理应是1030，但被压缩之后就变成了5，而这个1030被赋予给了外层的offset。当消费者消费这个消息集的时候，首先解压缩整个消息集，然后找到内层消息中最后一条消息的inner offset</p>
<p>对于压缩的情形，外层消息的timestamp设置为：</p>
<ul>
<li>如果timestamp类型是CreateTime，那么设置的是内层消息中最大的时间戳</li>
<li>如果timestamp类型是LogAppendTime，那么设置的是Kafka服务器当前的时间戳</li>
</ul>
<p>内层消息的timestamp设置为：</p>
<ul>
<li>如果timestamp类型是CreateTime，那么设置的是生产者创建消息时的时间戳</li>
<li>如果timestamp类型是LogAppendTime，那么所有内层消息的时间戳都会被忽略</li>
</ul>
<h3 id="V2版本"><a href="#V2版本" class="headerlink" title="V2版本"></a>V2版本</h3><p><img src="/media/15842495802579.jpg" alt="-w692"><br>v2版本中消息集称为Record Batch，而不是先前的Message Set，其内部也包含了一条或多条消息。在消息压缩的情形下，Record Batch Header部分（从first offset到records count字段）是不被压缩的，而被压缩的是records字段中的所有内容。生产者客户端中的ProducerBatch对应这里的RecordBatch，而ProducerRecord对应这里的Record<br>Record的内部字段大量采用了Varints（变长整型），这样Kafka可以根据具体的值来确定需要几个字节来保存</p>
<ul>
<li>length：消息总长度</li>
<li>attributes：弃用，但还是在消息格式中占据1B的大小</li>
<li>timestamp delta：时间戳增量。通常一个timestamp需要占用8个字节，如果向这里一样保存与RecordBatch的起始时间戳的差值，则可以进一步节省占有的字节数</li>
<li>offset delta：位移增量。保存与RecordBatch起始位移的差值</li>
<li>headers：Header包含key和value，一个Record里面可以包含0至多个Header</li>
</ul>
<p>v2版本对RecordBatch做了彻底的修改</p>
<ul>
<li>first offset：表示当前RecordBatch的起始位置</li>
<li>length：计算从partition leader epoch字段开始到末尾的长度</li>
<li>partition leader epoch：分区leader纪元，可以看作分区leader的版本号或更新次数</li>
<li>magic：消息格式的版本号，v2版本值为2</li>
<li>attributes：消息属性，这里占用了两个字节。低3位表示压缩格式，同v0和v1；第4位表示时间戳类型；第5位表示此RecordBatch是否处于事务中，0表示非事务，1表示事务。第6位表示是否是控制消息，0表示非控制消息，而1表示是控制消息，控制消息用来支持事务功能</li>
<li>last offset delta：RecordBatch中最后一个Record的offset与first offset的差值</li>
<li>first timestamp：RecordBatch中第一条Record的时间戳</li>
<li>max timestamp：RecordBatch中最大的时间戳</li>
<li>producer id：PID,用来支持幂等和事务</li>
<li>producer epoch：用来支持幂等和事务</li>
<li>first sequence：用来支持幂等和事务</li>
<li>records count：RecordBatch中Record的个数</li>
</ul>
<h2 id="日志索引"><a href="#日志索引" class="headerlink" title="日志索引"></a>日志索引</h2><p>偏移量索引文件用来建立消息偏移量到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳来查找对应的偏移量信息</p>
<p>Kafka中的索引文件以稀疏索引的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由broker端参数log.index.interval.bytes指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值对应地可以增加或缩小索引项的密度</p>
<p>稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中</p>
<p>日志分段文件切分包含以下几个条件，满足其一即可：</p>
<ul>
<li>当前日志分段文件的大小超过了broker端参数log.segment.bytes配置的值，log.segment.bytes参数的默认值为1073741824，即1GB</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天</li>
<li>偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。默认值为10485760，即10MB</li>
<li>追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE（offset-baseOffset&gt;Integer.MAX_VALUE）</li>
</ul>
<p>对非当前活跃的日志分段而言，其对应的索引文件内容已经固定而不需要再写入索引项，所以会被设定为只读。而对当前活跃的日志分段而言，索引文件还会追加更多的索引项，所以被设定为可读写。在索引文件切分的时候，Kafka会关闭当前正在写入的索引文件并置为只读模式，同时以可读写的模式创建新的索引文件，索引文件的大小由broker端参数log.index.size.max.bytes配置。Kafka在创建索引文件的时候会为其预分配log.index.size.max.bytes大小的空间，只有当索引文件进行切分的时候，Kafka才会把该索引文件裁剪到实际的数据大小。也即是说，与当前活跃的日志分段对应的索引文件的大小固定位log.index.size.max.bytes，而其余日志分段对应的索引文件的大小为实际的占用空间</p>
<h3 id="偏移量索引"><a href="#偏移量索引" class="headerlink" title="偏移量索引"></a>偏移量索引</h3><p><img src="/media/15842497275763.jpg" alt=""></p>
<ul>
<li>relativeOffset：相对偏移量，表示消息相对于baseOffset的偏移量，占用4个字节，当前索引文件的文件名即为baseOffset的值</li>
<li>position：物理地址，也就是消息在日志分段文件中对应的物理位置，占用4个字节</li>
</ul>
<p>消息的偏移量占用8个字节，也可以称为绝对偏移量。索引项中没有直接使用绝对偏移量而改为只占用4个字节的相对偏移量（relativeOffset=offset-baseOffset），这样可以减少索引文件占用的空间<br><img src="/media/15842497677950.jpg" alt="-w697"><br>如果要查找偏移量为23的消息，首先通过二分法在偏移量索引文件中找到不大于23的最大索引，即[22,656]，然后从日志分段文件中的物理位置656开始顺序查找偏移量为23的消息<br><img src="/media/15842497819362.jpg" alt=""><br>如果要找到偏移量为268的消息，先定位到baseOffset为251的日志分段，然后计算相对偏移量relativeOffset=268-251=17，之后再在对应的索引文件中找到不大于17的索引项，最后根据索引项中的position定位到具体的日志分段文件位置开始查找目标消息。查找baseOffset为251的日志分段用了跳跃表的结构，Kafka的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段</p>
<p>Kafka强制要求索引文件大小必须是索引项大小的整数倍，对偏移量索引文件而言，必须为8的整数。如果broker端参数log.index.size.max.bytes配置为67，那么Kafka在内部会将其转换为64，即不大于67，并且满足为8的整数倍的条件</p>
<h3 id="时间戳索引"><a href="#时间戳索引" class="headerlink" title="时间戳索引"></a>时间戳索引</h3><p><img src="/media/15842498132402.jpg" alt=""><br>每个索引项占用12个字节，分为两个部分</p>
<ul>
<li>timestamp：当前日志分段最大的时间戳</li>
<li>relativeOffset：时间戳所对应的消息的相对偏移量</li>
</ul>
<p>时间戳索引文件中包含若干个时间戳索引项，每个住家的时间戳索引项中的timestamp必须大于之前追加的索引项的timestamp，否则不予追加。如果broker端参数log.message.timestamp.type设置为LogAppendTime，那么消息的时间戳必定能够保持单调递增；相反，如果是CreateTime类型则无法保证。生产者可以使用类似ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)的方法指定时间戳的值。即使生产者客户端采用自动插入的时间戳也无法保证时间戳能够单调递增，如果两个不同时钟的生产者同时往一个分区中插入消息，那么也会造成当前分区的时间戳乱序</p>
<p>时间戳索引文件大小是索引项大小（12B）的整数倍，如果不满足条件也会进行裁剪。同样假设broker端参数log.index.size.max.bytes配置为67，那么对应于时间戳索引文件，Kafka在内部会将其转换为60</p>
<p><img src="/media/15842498547813.jpg" alt="-w781"><br>如果要查找指定时间戳targetTimeStamp=1526384718288开始的消息，首先是找到不小于指定时间戳的日志分段。这里就无法使用跳跃表来快速定位到相应的日志分段了。<br>1）将targetTimeStamp和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于targetTimeStamp的largestTimeStamp所对应的日志分段。日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间<br>2）找到相应的日志分段之后，在时间戳索引文件中使用二分法查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283,28]，如此便找到了相对偏移量28<br>3）在偏移量索引文件中使用二分法查找到不大于28的最大索引项，即[26,838]<br>4）从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息</p>
<h2 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h2><p>Kafka提供了两种日志清理策略：</p>
<ul>
<li>日志删除：按照一定的保留策略直接删除不符合条件的日志分段</li>
<li>日志压缩：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本</li>
</ul>
<p>可以通过broker端参数log.cleanup.policy来设置日志清理策略，此参数的默认值为delete，即采用日志删除的清理策略。如果要采用日志压缩的清理策略，就需要将log.cleanup.policy设置为compact，并且还需要将log.cleaner.enable（默认值为true）设定为true。通过将log.cleanup.policy设置为”delete,compact”，还可以同时支持日志删除和日志压缩两种策略。日志清理的粒度可以控制到主题级别</p>
<h3 id="日志删除"><a href="#日志删除" class="headerlink" title="日志删除"></a>日志删除</h3><p>在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过broker参数log.retention.check.interval.ms来配置，默认值为300000，即5分钟。当前日志分段的保留策略有3种：基于时间的保留策略、基于日志大小的保留策略和基于日志起始偏移量的保留策略</p>
<h4 id="基于时间"><a href="#基于时间" class="headerlink" title="基于时间"></a>基于时间</h4><p><img src="/media/15842499994189.jpg" alt=""><br>日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）。retentionMs可以通过broker端参数log.retention.hours、log.retention.minutes和log.retention.ms来配置，其中log.retention.ms优先级最高，默认情况下只配置了log.retention.hours参数，其值为168，默认情况下日志分段文件的保留时间为7天</p>
<p>若待删除的日志分段的总数等于该日志文件中所有的日志分段的数量，那么说明所有的日志分段都已过期，但该日志文件中还要有一个日志分段用于接收消息的写入，即必须要保证有一个活跃的日志分段activeSegment，在此种情况下，会先切出一个新的日志分段作为activeSegment，然后执行删除操作</p>
<p>删除日志分段时，首先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上”.deleted”的后缀。最后交由一个以”delete-file”命名的延迟任务来删除这些以”.deleted”为后缀的文件，这个任务的延迟执行时间可以通过file.delete.delay.ms参数来调配，此参数的默认值为60000，即1分钟</p>
<h4 id="基于日志大小"><a href="#基于日志大小" class="headerlink" title="基于日志大小"></a>基于日志大小</h4><p><img src="/media/15842500233532.jpg" alt=""><br>日志删除任务会检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments），retentionSize可以通过broker端参数log.retention.bytes来配置，默认值为-1，表示无穷大。log.retention.bytes配置的是Log中所有日志文件的总大小，而不是单个日志分段的大小。单个日志分段的大小由broker端参数log.segment.bytes来限制，默认值为1073741824，即1GB</p>
<p>基于日志大小的保留策略与基于时间的保留策略类似，首先计算日志文件的总大小size和retentionSize的差值diff，即计算需要删除的日志总大小，然后从日志文件中的第一个日志分段开始进行查找可删除的日志分段的文件集合deletableSegments。查找出deletableSegments之后就执行删除操作，这个删除操作和基于时间的保留策略的删除操作相同</p>
<h4 id="基于日志起始偏移量"><a href="#基于日志起始偏移量" class="headerlink" title="基于日志起始偏移量"></a>基于日志起始偏移量</h4><p><img src="/media/15842500526379.jpg" alt=""><br>一般情况下，日志文件的起始偏移量logStartOffset等于第一个日志分段的baseOffset，但并不是绝对的，logStartOffset的值可以通过DeleteRecordsRequest请求（KafkaAdminClient的deleteRecords()方法、使用kafka-delete-records脚本）、日志的清理和阶段等操作进行修改</p>
<p>基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于等于logStartOffset，若是，则可以删除日志分段。上图中，假设logStartOffset等于25，日志分段1的起始偏移量为0，日志分段2的起始偏移量为11，日志分段3的起始偏移量为23，通过如下动作收集可删除的日志分段的文件集合deletableSegments：</p>
<ul>
<li>A.从头开始遍历每个日志分段，日志分段1的下一个日志分段的起始偏移量为11，小于logStartOffset的大小，将日志分段1加入deletableSegments</li>
<li>B.日志分段2的下一个日志偏移量的起始偏移量为23，也小于logStartOffset的大小，将日志分段2加入deletableSegments</li>
<li>C.日志分段3的下一个日志偏移量在logStartOffset的右侧，故从日志分段3开始的所有日志分段都不会加入deletableSegments</li>
</ul>
<p>收集完可删除的日志分段的文件集合之后的删除操作同基于日志大小的保留策略和基于时间的保留策略相同</p>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>Kafka中的Log Compaction是指在默认的日志删除规则之外提供的一种清理过时数据的方式，会定期将相同key的消息进行合并，只保留最新的value值<br><img src="/media/15842501267485.jpg" alt="-w586"><br>Log Compaction执行前后，日志分段中的每条消息的偏移量和写入时的偏移量保持一致，Log Compaction会生成新的日志分段文件，日志分段中每条消息的物理地址会重新按照新文件来组织。Log Compaction执行过后的偏移量不再是连续的，不过不会影响日志的查询<br><img src="/media/15842501563334.jpg" alt="-w734"><br>每一个日志目录下都有一个名为”cleaner-offset-checkpoint”的文件，这个文件就是清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。通过清理检查点文件可以将Log分成两个部分。如上图所示，通过检查点cleaner checkpoint来划分出一个已经清理过的clean部分和一个还没清理的dirty部分。在日志清理的同时，客户端也可以读取日志中的消息。dirty部分的消息偏移量是逐一递增的，而clean部分的消息偏移量是断续的</p>
<p>firstDirtyOffset表示dirty部分的起始偏移量，而firstUncleanableOffset为dirty部分的截止偏移量，整个dirty部分的偏移量分为为[firstDirtyOffset,firstUncleanableOffset)。为了避免当前活跃的日志分段activeSegment成为热点文件，activeSegment不会参与Log Compaction</p>
<p>Log Compaction是针对key的，所以在使用时应注意每个消息的key值不为null。每个broker会启动log.cleaner.thread（默认值为1）个日志清理线程负责执行清理任务，这些线程会选择污浊率最高的日志文件进行清理。用cleanBytes表示clean部分的日志占用大小，dirtyBytes表示dirty部分的日志占用大小，那么这个日志的污浊率为：dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)</p>
<p>为了防止日志比较的频繁清理操作，Kafka还使用了参数log.cleaner.min。cleanable.ratio（默认值为0.5）来限定可进行清理操作的最小污浊率。Kafka中用于保留消费者位移的主题__consumer_offsets使用的就是Log Compaction策略</p>
<h2 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a>磁盘存储</h2><p>Kafka依赖于磁盘来存储和缓存消息。Kafka在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作</p>
<h3 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h3><p>页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变成对内存的访问</p>
<p>当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页是否在页缓存中，如果存在则直接返回数据，从而避免了对物理磁盘的I/O操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性</p>
<p>Kafka中大量使用了页缓存，这是Kafka实现高吞吐的重要因素之一。虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的，但在Kafka中同样提供了同步刷盘及间断性强制刷盘的功能，这些功能可以通过log.flush.interval.message、log.flush.interval.ms等参数来控制。同步刷盘可以提高消息的可靠性，防止由于机器掉电等异常造成处于页缓存而没有及时写入磁盘的消息丢失。消息的可靠性应该由多副本机制来保障，而不是由同步刷盘这种严重影响性能的行为来保障</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>除了消息顺序追加、页缓存等技术，Kafka还使用零拷贝技术来进一步提升性能。零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对于Linux操作系统而言，零拷贝技术依赖于底层的sendfile()方法实现。对应于Java语言，FileChannal.transferTo()方法的底层实现就是sendfile()方法</p>
<p>将静态内容展示给用户这个情形就意味着需要先将静态内容从磁盘中复制出来放到一个内存buf中，然后将这个buf通过套接字传输给用户，进而用户获得静态内容<br><img src="/media/15842502461853.jpg" alt="-w501"><br>A.调用read()时，文件A中的内容被复制到了内核模式下的Read Buffer中<br>B.CPU控制将内核模式数据复制到用户模式下<br>C.调用write()时，将用户模式下的内容复制到内核模式下的Socket Buffer中<br>D.将内核模式下的Socket Buffer的数据复制到网卡设备中传送</p>
<p>采用零拷贝技术，应用程序可以直接请求内核把磁盘中的数据传输给Socket<br><img src="/media/15842502734149.jpg" alt="-w514"><br>零拷贝技术通过DMA（Direct Memory Access）技术将文件内容复制到内核模式下的Read Buffer中。不过没有数据被复制到Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer中。DMA引擎直接将数据从内核模式中传递到网卡设备。零拷贝是针对内核模式而言的，数据在内核模式下实现了零拷贝</p>
<h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p><a href="https://blog.csdn.net/qq_40378034/article/details/90487244" target="_blank" rel="noopener">https://blog.csdn.net/qq_40378034/article/details/90487244</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kakfa主题与分区/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kakfa主题与分区/" itemprop="url">kafka主题与分区</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-12T13:00:00+08:00">
                2020-03-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kafka主题与分区"><a href="#Kafka主题与分区" class="headerlink" title="Kafka主题与分区"></a>Kafka主题与分区</h1><p>主题和分区是Kafka的核心概念，主题是消息的归类，一个主题可以再次细分为一到多个分区，分区可以看作是消息的二次归类。主题和分区不仅为Kafka提供了可伸缩性，可扩展性，还可通过分区副本实现高可靠性。</p>
<h2 id="主题的管理"><a href="#主题的管理" class="headerlink" title="主题的管理"></a>主题的管理</h2><h3 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h3><p>创建主题有很多方式，可以是自动创建，也可以手动创建<br><strong>自动创建</strong><br>如果我们在配置文件中配置的<br><code>auto.create.topics.enable :true</code><br>那么当我们生产者向一个不存在的主题发送数据的时候，那么就会自动创建一个分区数为nums.partitions(默认1），副本数为default.replication.factor(默认为1)的主题，当然如果我们消费一个不存在的主题的时候，也会创建一个主题，分区和副本数会按照默认值进行创建。<br>但是我们一般在开发中是不建议开启自动创建的，因为这样会导致维护成本大，并且创建的主题是否规范等也是问题。</p>
<p><strong>手动创建</strong><br><code>./kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic_test --partitions 3 --replication-factor 2</code><br>我们执行上面的操作命令就创建了一个topic 为topic_test的主题，分区为3，副本为2.</p>
<p>Kafka会在log.dir/log.dirs参数所配置的目录下创建主题分区，默认是/tmp/kafka-logs<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls -al /tmp/kafka-logs | grep topic_test</span><br><span class="line">drwxr-xr-x    2 root  root    107 Sep 8 16:58 topic_test-1</span><br><span class="line">drwxr-xr-x    2 root  root    107 Sep 8 16:58 topic_test-2</span><br></pre></td></tr></table></figure></p>
<p>可以看到，创建了两个文件夹，后面的数字代表的是分区号，一般文件夹的格式为：主题-分区号<br>由于分区*副本会根据broker数量分配在不同的broker中，所以每个broker看到的分区信息是不同的。同一个分区中的多个副本必须分布在不同的broker中，才能提供有效的数据冗余</p>
<p><img src="/media/15842413366557.jpg" alt="-w459"></p>
<p>除此之外还可以通过zookeeper进行查看配置信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">get  /broker/topics/topic_test</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:&#123;&quot;0&quot;: [1,2], &quot;1&quot;: [0,1], &quot;2&quot;: [0,2]&#125;&#125;</span><br></pre></td></tr></table></figure></p>
<p>创建主题时的分区副本都是按照既定的内部逻辑来进行分配的。kafka-topics.sh 脚本中还提 供了一个replica-assignment参数手动指定分区副本的分配方案。<br><code>./kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-create-same --replica-assignment 2:0,0:1,1:2,2:1</code><br>这种方式根据分区号的数值大小按照从小到大的顺序进行排序，分区与分区之间用逗号,隔开，分区内多个副本用冒号:隔开。并且在使用–replica-assignment参数创建主题时不需要原本必备的partitions和replication-factor这两个参数。创建时注意同一分区内的副本不能有重复</p>
<h3 id="查看主题"><a href="#查看主题" class="headerlink" title="查看主题"></a>查看主题</h3><p>查看主题有两个相关的命令，一个是list,一个是describe，list命令是显示出我们创建的所有主题，describe是显示某个主题的相关信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic_test</span><br><span class="line">Topic:topic_test PartitionCount:3    ReplicationFactor:2 Configs:</span><br><span class="line">    Topic: topic_test    Partition: 0    Leader: 0   Replicas: 0,1   Isr: 0,1</span><br><span class="line">    Topic: topic_test    Partition: 1    Leader: 1   Replicas: 1,2   Isr: 1,2</span><br><span class="line">    Topic: topic_test    Partition: 2    Leader: 2   Replicas: 2,0   Isr: 2,0</span><br></pre></td></tr></table></figure>
<p>在查看主题的时候，我们还可以指定参数，来显示有问题的主题分区<br>under-replicated-partitions 找出包含失效副本的分区<br>unavailable-partitions 查看主题中没有leader副本的分区</p>
<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><p>在我们创建了主题之后,我们可以修改我们创建的主题,比如修改分区的个数,主题的配置等,主要通过关键字alert来实现。</p>
<p><strong>修改分区</strong><br>./kafka-topics.sh –zookeeper localhost:2181/kafka  –alter –topic topic_test –partitions 4</p>
<p>说明：<br>    1、如果我们的主题消息中包含key时，那么根据key计算分区的行为就会受到影响，因为计算分区是需要根据key的值来计算的<br>    2、还会影响消息的顺序问题，所以建议应该是先创建好主题，避免后期修改<br>说明：<br>kafka只支持增加分区，现在还不能支持<strong>减少分区</strong>。因为如果减少分区会有所影响，比如有下面这几方面影响<br>    1、删除的分区消息如何处理<br>    2、在分区数据在复制期间可能性如何保证<br>    3、分区进行删除的时候占用资源等<br>    最好的方式就是创建一个新的主题，然后将现在主题的数据复制过去</p>
<p><strong>修改配置</strong><br>我们可以利用alter来修改在创建主题时候指定的配置信息，可以将原来的配置给覆盖掉。<br><code>./kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic_test  --config max.message.bytes=500</code><br>通过上面的命令，把原来的配置config max.message.bytes 修改为500</p>
<p><strong>删除配置</strong><br>我们可以使用delete-config来删除之前我们修改的配置，让这个值恢复到原有的默认值<br><code>./kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic_test  --delete-config max.message.bytes=500</code><br>上面的命令会让配置max.message.bytes恢复成默认值1000</p>
<h3 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h3><p>在kafka的bin路径下面，有kafka-configs.sh脚本，这个脚本主要是对配置进行管理，指的是我们的kafka在运行的状态，能够动态的进行修改，这个命令不仅能修改主题相关的配置，还能修改broker，用户，客户端等方面的配置。这个命令需要两个参数，一个是entity-type，用来指定操作配置的类型，比如是topic还是其他，另外一个就是entity-name，用来表示操作配置的名称。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./kafka-configs.sh --zookeeper localhost:2181/kafka --describe --entity-type topics --entity-name topic_test</span><br><span class="line">Configs for topic &apos;topic_test&apos; are max.message.bytes=1000</span><br></pre></td></tr></table></figure>
<p>entity-type的取值有下面几种：<br>topics: 主题相关<br>brokers: broker类型的配置<br>clients: 客户端类型的配置<br>users: 用户类型的配置<br>在使用alter进行变更配置的时候，会和add-config和delete-config配合使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-configs.sh --zookeeper localhost:2181/kafka --alter --entity-type topics --entity-name topic_test --add-config max.message.bytes=800</span><br></pre></td></tr></table></figure>
<h3 id="删除主题"><a href="#删除主题" class="headerlink" title="删除主题"></a>删除主题</h3><p>当我们的主题不在被需要的时候，我们可以把主题删除了，这样的释放资源，比如磁盘空间，文件句柄等。</p>
<p><code>./kafka-topics.sh --zookeeper localhost:2181/kafka --delete --topic topic_test</code></p>
<p>说明：<br>1、我们可以删除我们创建的主题，无法删除kafka内部自己的主题，比如<strong>consumer_offsets, </strong>transaction_state<br>2、删除一个不存在的主题也会报错，为了避免，我们可以加上参数–if-exists</p>
<p>其实删除主题本质上，只是在zk的、admin/delete_topics下创建一个待删除主题同名的节点，表示这个主题是要删除的，但是真正执行删除的动作是由kafka的控制器负责完成的。</p>
<p>补充：<br>手动删除主题，主题中的元数据是在/brokers/topics和/config/topics下面，主题的数据内容是在log.dir目录下面<br>所以如果我们手动删除的话，那么就在这几个地方把相关数据删除即可<br>1、删除/brokers/topics下需要删除的主题<br>2、删除/config/topics下需要删除的主要的配置<br>3、删除log.dir或者log.dirs下的数据内容</p>
<h2 id="初识KafkaAdminClient"><a href="#初识KafkaAdminClient" class="headerlink" title="初识KafkaAdminClient"></a>初识KafkaAdminClient</h2><h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>KafkaAdminClient继承了org.apache.kafka.clients.admin.AdminClient抽象类，主要方法如下：</p>
<ul>
<li>创建主题：CreateTopicsResult createTopics(Collection<newtopic> newTopics)</newtopic></li>
<li>删除主题：DeleteTopicsResult deleteTopics(Collection<string> topics)</string></li>
<li>列出所有可用的主题：ListTopicsResult listTopics()</li>
<li>查看主题的信息：DescribeTopicsResult describeTopics(Collection<string> topicNames)</string></li>
<li>查询配置信息：DescribeConfigsResult describeConfigs(Collection<configresource> resources)</configresource></li>
<li>修改配置信息：AlterConfigsResult alterConfigs(Map&lt;ConfigResource, Config&gt; configs)</li>
<li>增加分区：CreatePartitionsResult createPartitions(Map&lt;String, NewPartitions&gt; newPartitions)</li>
</ul>
<h3 id="创建主题-1"><a href="#创建主题-1" class="headerlink" title="创建主题"></a>创建主题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest</span><br><span class="line">public class KafkaAdminTest &#123;</span><br><span class="line">    @Test</span><br><span class="line">    public void createTopic() &#123;</span><br><span class="line">        String brokerList = &quot;192.168.126.158:9092&quot;;</span><br><span class="line">        String topic = &quot;topic-admin&quot;;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);</span><br><span class="line">        AdminClient client = AdminClient.create(props);</span><br><span class="line">        NewTopic newTopic = new NewTopic(topic, 4, (short) 1);</span><br><span class="line">        CreateTopicsResult result = client.createTopics(Collections.singleton(newTopic));</span><br><span class="line">        try &#123;</span><br><span class="line">            result.all().get();</span><br><span class="line">        &#125; catch (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            client.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AdminClient.create()方法实际上调用的就是KafkaAdminClient中的createInternal方法构建的KafkaAdminClient实例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public static AdminClient create(Properties props) &#123;</span><br><span class="line">       return KafkaAdminClient.createInternal(new AdminClientConfig(props), null);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>NewTopic用来设定所要创建主题的具体信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public class NewTopic &#123;</span><br><span class="line">    private final String name;//主题名称</span><br><span class="line">    private final int numPartitions;//分区数</span><br><span class="line">    private final short replicationFactor;//副本因子</span><br><span class="line">    private final Map&lt;Integer, List&lt;Integer&gt;&gt; replicasAssignments;//分配方案</span><br><span class="line">    private Map&lt;String, String&gt; configs = null;//配置</span><br></pre></td></tr></table></figure>
<p>可以通过指定分区数和副本因子来创建一个主题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Integer, List&lt;Integer&gt;&gt; replicasAssignments = new HashMap&lt;&gt;();</span><br><span class="line">replicasAssignments.put(0, Arrays.asList(0));</span><br><span class="line">replicasAssignments.put(1, Arrays.asList(0));</span><br><span class="line">replicasAssignments.put(2, Arrays.asList(0));</span><br><span class="line">replicasAssignments.put(3, Arrays.asList(0));</span><br><span class="line">NewTopic newTopic = new NewTopic(topic, replicasAssignments);</span><br></pre></td></tr></table></figure>
<p>也可以在创建主题时指定需要覆盖的配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; configs=new HashMap&lt;&gt;();</span><br><span class="line">configs.put(&quot;cleanup.policy&quot;,&quot;compact&quot;);</span><br><span class="line">newTopic.configs(configs);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class CreateTopicsResult &#123;</span><br><span class="line">    private final Map&lt;String, KafkaFuture&lt;Void&gt;&gt; futures;</span><br><span class="line"></span><br><span class="line">    CreateTopicsResult(Map&lt;String, KafkaFuture&lt;Void&gt;&gt; futures) &#123;</span><br><span class="line">        this.futures = futures;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Map&lt;String, KafkaFuture&lt;Void&gt;&gt; values() &#123;</span><br><span class="line">        return futures;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public KafkaFuture&lt;Void&gt; all() &#123;</span><br><span class="line">        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CreateTopicsResult中的方法主要是针对成员变量futures的操作，futures的类型Map&lt;String, KafkaFuture<void>&gt;中的key代表主题名称，而KafkaFuture<void>代表创建后的返回值类型。KafkaAdminClient中的createTopics()方法可以一次性创建多个主题。KafkaFuture实现了Future接口，可以通过Future.get()方法来等待服务端的返回</void></void></p>
<p>KafkaAdminClient中的listTopics()方法的返回值为ListTopicsResult类型，这个ListTopicsResult类型内部的成员变量future的类型为KafkaFuture&lt;Map&lt;String, TopicListing&gt;&gt;，这里包含了具体的返回信息</p>
<p>使用close()方法释放资源</p>
<h3 id="查看主题具体配置信息"><a href="#查看主题具体配置信息" class="headerlink" title="查看主题具体配置信息"></a>查看主题具体配置信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">String brokerList = &quot;192.168.126.158:9092&quot;;</span><br><span class="line">String topic = &quot;topic-admin&quot;;</span><br><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);</span><br><span class="line">AdminClient client = AdminClient.create(props);</span><br><span class="line">ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, topic);</span><br><span class="line">DescribeConfigsResult result = client.describeConfigs(Collections.singleton(resource));</span><br><span class="line">Config config = result.all().get().get(resource);</span><br><span class="line">System.out.println(config);</span><br><span class="line">client.close();</span><br></pre></td></tr></table></figure>
<h3 id="修改主题配置信息"><a href="#修改主题配置信息" class="headerlink" title="修改主题配置信息"></a>修改主题配置信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, topic);</span><br><span class="line">ConfigEntry entry = new ConfigEntry(&quot;cleanup.policy&quot;, &quot;compact&quot;);</span><br><span class="line">Config config = new Config(Collections.singleton(entry));</span><br><span class="line">Map&lt;ConfigResource, Config&gt; configs = new HashMap&lt;&gt;();</span><br><span class="line">configs.put(resource, config);</span><br><span class="line">AlterConfigsResult result = client.alterConfigs(configs);</span><br><span class="line">result.all().get();</span><br></pre></td></tr></table></figure>
<h3 id="修改分区"><a href="#修改分区" class="headerlink" title="修改分区"></a>修改分区</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NewPartitions newPartitions = NewPartitions.increaseTo(5);</span><br><span class="line">Map&lt;String, NewPartitions&gt; newPartitionsMap = new HashMap&lt;&gt;();</span><br><span class="line">newPartitionsMap.put(topic, newPartitions);</span><br><span class="line">CreatePartitionsResult result = client.createPartitions(newPartitionsMap);</span><br><span class="line">result.all().get();</span><br></pre></td></tr></table></figure>
<h3 id="主题合法性验证"><a href="#主题合法性验证" class="headerlink" title="主题合法性验证"></a>主题合法性验证</h3><p>Kafka broker端create.topic.policy.class.name参数，默认值为null，它提供了一个入口用来验证主题创建的合法性，需要自定义实现org.apache.kafka.server.policy.CreateTopicPolicy接口，然后在broker端的配置文件config/server.properties中配置参数create.topic.policy.class.name的值</p>
<p>主要实现接口的configure()、close()和validate()方法，configure()方法会在Kafka服务启动的时候执行，validate()方法用来鉴定主题参数的合法性，在创建主题时执行，close()方法在关闭Kafka服务时执行</p>
<h2 id="分区管理"><a href="#分区管理" class="headerlink" title="分区管理"></a>分区管理</h2><h3 id="优先副本的选举"><a href="#优先副本的选举" class="headerlink" title="优先副本的选举"></a>优先副本的选举</h3><p>在创建主题的时候，该主题的分区及副本会尽可能均匀地分布到Kafka集群的各个broker节点上，对应的leader副本的分配也比较均匀<br>当分区的leader节点发生故障时，其中一个follower节点就会成为新的leader节点，这样就会导致集群的负载不均衡。当原来的leader节点恢复之后重新加入集群时，它只能成为一个新的follower节点而不再对外提供服务<br>优先副本是指在AR集合列表中的第一个副本。优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也可以称为分区平衡</p>
<p>Kafka提供分区自动平衡的功能，与此对应的broker参数是auto.leader.rebalance.enable，此参数的默认值为true，默认情况下此功能是开启的。如果开启分区自动平衡的功能，则Kafka的控制器会启动一个定时任务，这个定时任务会轮询所有的broker节点，计算每个broker节点的分区不平衡率（broker中的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认值为10%，如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。执行周期由参数leader.imbalance.check.interval.seconds控制，默认值为300秒，即5分钟</p>
<h3 id="分区重分配"><a href="#分区重分配" class="headerlink" title="分区重分配"></a>分区重分配</h3><p>分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制所有的数据。根据分区的大小不同，复制过程可能需要花一些时间，因为数据是通过网络复制到新副本上的。在复制完成之后，控制器将旧副本从副本清单里移除（恢复为原先的副本因子）。在重分配的过程中要确保有足够的空间</p>
<h3 id="复制限流"><a href="#复制限流" class="headerlink" title="复制限流"></a>复制限流</h3><p>对副本间的复制流量加以限制来保证重分配期间整体服务不会受太大的影响</p>
<p>kafka-configs.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：follower.replication.throttled.rate和leader.replication.throttled.rate，前者用于设置follower副本复制的速度，后者用于设置leader副本传输的速度，它们的单位都是B/s。通过情况下，两者的配置值是相同的。下面将broker1中的leader副本和follower副本的复制速度限制在1024B/s之内</p>
<h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p><a href="https://zhuanlan.zhihu.com/p/93790595" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/93790595</a><br><a href="https://blog.csdn.net/qq_40378034/article/details/90487244" target="_blank" rel="noopener">https://blog.csdn.net/qq_40378034/article/details/90487244</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/面试整理/计算机网络/计算机网络面试整理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/面试整理/计算机网络/计算机网络面试整理/" itemprop="url">计算机网络面试整理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-03T13:00:00+08:00">
                2020-03-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="计算机网络面试整理"><a href="#计算机网络面试整理" class="headerlink" title="计算机网络面试整理"></a>计算机网络面试整理</h1><p><a href="http://www.justdojava.com/2019/11/03/Network_interview_question/" target="_blank" rel="noopener">http://www.justdojava.com/2019/11/03/Network_interview_question/</a></p>
<h2 id="TCP-IP"><a href="#TCP-IP" class="headerlink" title="TCP/IP"></a>TCP/IP</h2><ol>
<li>http请求流程 ，三次握手四次挥手<br> <a href="https://blog.csdn.net/qzcsu/article/details/72861891" target="_blank" rel="noopener">https://blog.csdn.net/qzcsu/article/details/72861891</a><br> <img src="/media/15833191149539.jpg" alt="-w877"><br><img src="/media/15833191282591.jpg" alt="-w856"></li>
</ol>
<ol start="2">
<li><p>为什么TCP链接需要三次握手，两次不可以么，为什么？<br> 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。<br> 如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。<br> 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。</p>
</li>
<li><p>tcp四次挥手的过程？TIME_WAIT为什么至少设置两倍的MSL时间？<br> MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。<br> 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。<br> 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。</p>
</li>
<li><p>为什么建立连接是三次握手，关闭连接确是四次挥手呢？<br> 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。<br> 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。</p>
</li>
<li><p>如果已经建立了连接，但是客户端突然出现故障了怎么办？<br> TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>
</li>
<li><p>TCP协议如何来保证传输的可靠性<br> TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。<br>对于可靠性，TCP通过以下方式进行保证：</p>
<ul>
<li>数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；</li>
<li>对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；</li>
<li>丢弃重复数据：对于重复数据，能够丢弃重复数据；</li>
<li>应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；</li>
<li>超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；</li>
<li>流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。</li>
</ul>
</li>
<li><p>客户端不断进行请求链接会怎样？DDos(Distributed Denial of Service)攻击？<br> 服务器端会为每个请求创建一个链接，并向其发送确认报文，然后等待客户端进行确认<br> 1)、DDos 攻击</p>
<pre><code>客户端向服务端发送请求链接数据包
服务端向客户端发送确认数据包
客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认
</code></pre><p> 2)、DDos 预防 (没有彻底根治的办法，除非不使用TCP )</p>
<pre><code>限制同时打开SYN半链接的数目
缩短SYN半链接的Time out 时间
关闭不必要的服务
</code></pre></li>
<li><p>TCP与UDP的区别<br>TCP (Transmission Control Protocol)和UDP(User Datagram Protocol)协议属于传输层协议，它们之间的区别包括：<br> TCP是面向连接的，UDP是无连接的；<br> TCP是可靠的，UDP是不可靠的；<br> TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多的通信模式；<br> TCP是面向字节流的，UDP是面向报文的；<br> TCP有拥塞控制机制;UDP没有拥塞控制，适合媒体通信；<br> TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大；</p>
</li>
<li><p>TCP的拥塞处理<br> 计算机网络中的带宽、交换结点中的缓存及处理机等都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就会变坏，这种情况就叫做拥塞。拥塞控制就是 防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载。注意，拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。拥塞控制的方法主要有以下四种：<br> 1).慢启动：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小;<br> 2).拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍，这样拥塞窗口按线性规律缓慢增长。<br> 3).快重传：快重传要求接收方在收到一个 失序的报文段 后就立即发出 重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。<br> 4).快恢复：快重传配合使用的还有快恢复算法，当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半，但是接下去并不执行慢开始算法：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。<br> <img src="/media/15833222476248.jpg" alt=""></p>
</li>
<li><p>TCP和UDP分别对应的常见应用层协议<br>1). TCP对应的应用层协议</p>
<pre><code>FTP：定义了文件传输协议，使用21端口
Telnet：它是一种用于远程登陆的端口
SMTP：定义了简单邮件传送协议
SSH: 22端口
POP3：它是和SMTP对应，POP3用于接收邮件
HTTP：从Web服务器传输超文本到本地浏览器的传送协议。
</code></pre><p>2). UDP对应的应用层协议</p>
<pre><code>DNS：用于域名解析服务， 53
SNMP：简单网络管理协议，使用161号端口
TFTP：简单文件传输协议， 69端口
</code></pre></li>
<li><p>udp怎么实现可靠传输</p>
</li>
<li><p>TCP报文首部</p>
</li>
</ol>
<h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><ol>
<li><p>Http和Https的区别</p>
<p> <strong>开销</strong>: https协议需要到CA（Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。<br> <strong>安全性</strong>: http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。<br> <strong>端口</strong>: http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。<br> <strong>资源消耗</strong>: 和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源</p>
</li>
<li><p>浏览器中输入一个URL后，按下回车后发生了什么<br> <a href="https://juejin.im/post/5d5e795ff265da03e275f29e" target="_blank" rel="noopener">https://juejin.im/post/5d5e795ff265da03e275f29e</a></p>
<p> (1) URL 解析</p>
<pre><code>地址解析: 判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。
HSTS: 由于安全隐患，有时会使用 HSTS 强制客户端使用 HTTPS 访问页面
其他操作: 浏览器还会进行一些额外的操作，比如安全检查、访问限制
检查缓存: 
</code></pre><p><img src="/media/15833117720004.jpg" alt=""></p>
<p> (2) DNS 查询<br> <img src="/media/15833118889356.jpg" alt=""><br> (3) TCP 连接<br> <img src="/media/15833120429749.jpg" alt=""><br> 应用层：发送 HTTP 请求</p>
<pre><code>在前面的步骤我们已经得到服务器的 IP 地址，浏览器会开始构造一个 HTTP 报文，其中包括：请求报头和请求主体
</code></pre><p> 传输层：TCP 传输报文<br> 网络层：IP协议查询Mac地址</p>
<pre><code>判断目标地址是否与当前地址处于同一网络中，是的话直接根据 Mac 地址发送，否则使用路由表查找下一跳地址，以及使用 ARP 协议查询它的 Mac 地址。
</code></pre><p> 链路层：以太网协议<br> (4) 服务器处理请求<br> <img src="/media/15833122604503.jpg" alt=""><br> (5) 浏览器接受响应<br> (6) 渲染页面<br><img src="/media/15833134601040.jpg" alt=""></p>
</li>
<li><p>http1.0, 1.1, 2.0的区别</p>
</li>
<li><p>HTTP长连接、短连接</p>
</li>
</ol>
<ol start="5">
<li></li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li><p>Get与POST的区别<br>GET与POST是我们常用的两种HTTP Method，二者之间的区别主要包括如下几个方面：<br>(1). 功能: GET一般用来从服务器上获取资源，POST一般用来更新服务器上的资源；<br>(2). REST服务角度: GET是幂等的，即读取同一个资源，总是得到相同的数据，而POST不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET不会改变服务器上的资源，而POST会对服务器资源进行改变；<br>(3). 请求参数形式: GET请求的数据会附在URL之后，即将请求数据放置在HTTP报文的 请求头 中，以?分割URL和传输数据，参数之间以&amp;相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如：%E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII)；而POST请求会把提交的数据则放置在是HTTP请求报文的 请求体中。GET只接受ASCII字符，而POST没有限制<br>(4). 安全性: POST的安全性要比GET的安全性高，因为GET请求提交的数据将明文出现在URL上，而且POST请求参数则被包装到请求体中，相对更安全。<br>(5). 请求大小: GET请求的长度受限于浏览器或服务器对URL长度的限制，允许发送的数据量比较小，而POST请求则是没有大小限制的。<br>(6) 缓存: GET请求会被浏览器主动cache，而POST不会，除非手动设置。<br>(7) 编码: GET请求只能进行url编码，而POST支持多种编码方式。</p>
</li>
<li><p>RESTFul 中PUT POST PATCH的区别<br> PUT：用来创建一个URL已知的资源，或对已知资源进行完全替换。一般用来更新一个已知资源，除非在创建前，自己完全知道要创建的对象的URL。<br> POST：用来创建一个子资源，不是幂等的，多次执行，将导致多条形同的资源被创建。<br> PATCH：是对PUT方法的补充，用来对已知资源进行局部更新。</p>
</li>
<li><p>Session、Cookie 与 Application<br> Cookie和Session都是客户端与服务器之间保持状态的解决方案，具体来说，cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。<br> (1). Cookie及其相关API<br>　　 Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie，而客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器，服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。<br> (2). Session及其相关API<br>　　 同样地，会话状态也可以保存在服务器端。客户端请求服务器，如果服务器记录该用户状态，就获取Session来保存状态，这时，如果服务器已经为此客户端创建过session，服务器就按照sessionid把这个session检索出来使用；如果客户端请求不包含sessionid，则为此客户端创建一个session并且生成一个与此session相关联的sessionid，并将这个sessionid在本次响应中返回给客户端保存。保存这个sessionid的方式可以采用 cookie机制 ，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器；若浏览器禁用Cookie的话，可以通过 URL重写机制将sessionid传回服务器。<br> (3). Session与Cookie 的对比<br> 实现机制：Session的实现常常依赖于Cookie机制，通过Cookie机制回传SessionID；<br> 大小限制：Cookie有大小限制并且浏览器对每个站点也有cookie的个数限制，Session没有大小限制，理论上只与服务器的内存大小有关；<br> 安全性：Cookie存在安全隐患，通过拦截或本地文件找得到cookie后可以进行攻击，而Session由于保存在服务器端，相对更加安全；<br> 服务器资源消耗：Session是保存在服务器端上会存在一段时间才会消失，如果session过多会增加服务器的压力。<br> (4). Application（ServletContext)<br> 与一个Web应用程序相对应，为应用程序提供了一个全局的状态，所有客户都可以使用该状态。</p>
</li>
<li><p>网络层的ARP协议工作原理<br> 网络层的ARP协议完成了IP地址与物理地址的映射。首先，每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己ARP列表中是否存在该IP地址对应的MAC地址：如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个ARP响应数据包，告诉对方自己是它需要查找的MAC地址；源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。</p>
</li>
<li><p>常见状态码及原因短语<br> 1×× : 请求处理中，请求已被接受，正在处理<br> 2×× : 请求成功，请求被成功处理， 200 OK<br> 3×× : 重定向，要完成请求必须进行进一步处理</p>
<pre><code>301 : 永久性转移
302 ：暂时性转移
304 ：已缓存
</code></pre><p> 4×× : 客户端错误，请求不合法</p>
<pre><code>400：Bad Request,请求有语法问题
403：拒绝请求
404：客户端所访问的页面不存在
</code></pre><p> 5×× : 服务器端错误，服务器不能处理合法请求</p>
<pre><code>500 ：服务器内部错误
503 ： 服务不可用，稍等
</code></pre></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka消费者/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/Kafka消费者/" itemprop="url">kafka消费者</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-29T13:00:00+08:00">
                2020-02-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h1><h2 id="消费者与消费组"><a href="#消费者与消费组" class="headerlink" title="消费者与消费组"></a>消费者与消费组</h2><p>一般有两种消息投递模式:点对点（P2P, Point-to-Point)模式和发布/订阅(Pub/Sub)模式<br>Kafka同时支持两种消息投递模式：</p>
<ul>
<li>点对点:如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。</li>
<li>发布订阅:如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。</li>
</ul>
<p>在 Kafka 中，消费者通常是消费者群组的一部分，多个消费者群组共同读取同一个主题时，彼此之间互不影响。<br><img src="/media/15829691705213.jpg" alt="-w359"></p>
<p>同一个分区只能被同一个消费者群组里面的一个消费者读取，一般不存在同一个分区被同一个消费者群里多个消费者共同读取的情况。因此合理设置消费者数量，提高消费能力的同时以及避免造成闲置和额外开销。<br><img src="/media/15829692652691.jpg" alt="-w356"></p>
<h2 id="消费者消费"><a href="#消费者消费" class="headerlink" title="消费者消费"></a>消费者消费</h2><p>一个正常的消费逻辑需要具备以下几个步骤:<br>(1) 配置消费者客户端参数及创建相应的消费者实例 。<br>(2) 订阅主题。<br>(3）拉取消息并消费<br>(4）提交消费位移 。<br>(5) 关闭消费者实例。</p>
<h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public class KafkaConsumers&#123;</span><br><span class="line">    public static final String brokerList = &apos;localhost:9200&apos;;</span><br><span class="line">    public static final String topic = &apos;topic-demo&apos;;</span><br><span class="line">    public static final String groupId = &apos;group.demo&apos;;</span><br><span class="line">    public static final AtomicBoolean isRunning = new AtomicBoolean(true);</span><br><span class="line"></span><br><span class="line">    public static Properties initConfig()&#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, brokerList);</span><br><span class="line">        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;group.id&quot;, groupId);</span><br><span class="line">        props.put(&quot;client.id&quot;, &quot;consumer.client.id.demo&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args)&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        // 订阅</span><br><span class="line">        consumer.subscribe(Arrays.asList(topic));</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            while(isRunning.get())&#123;</span><br><span class="line">                ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000));</span><br><span class="line">                for (ConsumerRecords&lt;String, String&gt; record: records)&#123;</span><br><span class="line">                    System.out.println(&apos;topic = &apos; + record.topic() + </span><br><span class="line">                        &apos;, partition = &apos; + record.partition());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e)&#123;</span><br><span class="line">            log.error(e);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            consumer.close()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>必要参数</strong></p>
<pre><code>1. bootstrap.servers 与生产者中的KafkaProducer中的相同
2. group.id消费组的名称, 默认值为&quot;&quot;， 设置为空，会报异常
3. key.deserializer 和 value.deserializer, 对应KafkaProducer的序列化方式。
</code></pre><h3 id="订阅主题与分区"><a href="#订阅主题与分区" class="headerlink" title="订阅主题与分区"></a>订阅主题与分区</h3><p>一个消费者可以订阅一个或多个主题，subscribe()方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public void subscribe(Collection&lt;String&gt; topics , ConsumerRebalanceListener listener)</span><br><span class="line">public void subscribe(Collection&lt;String&gt; topics)</span><br><span class="line">public void subscribe(Pattern pattern , ConsumerRebalanceListener listener) </span><br><span class="line">public void subscribe (Pattern pattern)</span><br></pre></td></tr></table></figure></p>
<p>支持正则订阅，如果先后多次订阅以最后的为准。</p>
<p><strong>订阅分区</strong><br>消费者不仅可以直接订阅主题，还可以订阅主题下的特定分区（assign()方法）<br><code>public void assign(Collection&lt;TopicPartition&gt; partitions)</code><br>例如订阅topic下的第0个分区:<br><code>consumer.assign(Arrays.asList(new TopicParitition(&quot;topic&quot;, 0)))</code></p>
<p>可通过partitionsFor()方法可以用来查询指定主题的元数据信息<br><code>public List&lt;PartitionInfo&gt; partitionsFor(String topic)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class PartitionInfo &#123;</span><br><span class="line">    private final String topic;</span><br><span class="line">    private final int partition;</span><br><span class="line">    private final Node leader;</span><br><span class="line">    private final Node[] replicas;</span><br><span class="line">    private final Node[] inSyncReplicas;</span><br><span class="line">    private final Node[] offlineReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>取消订阅</strong><br>    consumer.unsubscribe()；</p>
<h3 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h3><p>与生产者的序列化相对应，通常使用StringDeserializer。</p>
<h3 id="消息消费"><a href="#消息消费" class="headerlink" title="消息消费"></a>消息消费</h3><p>kafka消息消费就是重复性调用poll()方法。<br>public ConsumerRecords&lt;K, V&gt; poll(final Duration timeout)<br><img src="/media/15829710654294.jpg" alt="-w399"></p>
<h3 id="控制或关闭消费"><a href="#控制或关闭消费" class="headerlink" title="控制或关闭消费"></a>控制或关闭消费</h3><p><code>public void pause(Collection&lt;TopicPartition&gt; partitions)</code><br><code>public void resume(Collection&lt;TopicPartition&gt; partitions)</code><br>//返回被暂停的分区集合<br><code>public Set&lt;TopicPartition&gt; paused()</code><br>退出消费: consumer.wakeup()</p>
<h2 id="位移提交"><a href="#位移提交" class="headerlink" title="位移提交"></a>位移提交</h2><p>在每次调用 poll()方法时，它返回的是还没有被消费过的消息集<br>在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题_consumer_offsets中。消费者在消费完消息之后需要执行消费位移的提交。<br><img src="/media/15829712490391.jpg" alt="-w410"></p>
<h3 id="自动提交偏移量"><a href="#自动提交偏移量" class="headerlink" title="自动提交偏移量"></a>自动提交偏移量</h3><p>在 Kafka 中默认的消费位移的提交方式是自动提交，enable.auto.commit 属性配置为 true 即可完成自动提交的配置。此时每隔固定的时间，消费者就会把poll()方法接收到的最大偏移量进行提交，提交间隔由auto.commit.interval.ms 属性进行配置，默认值是 5s。<br>    自动位移提交的动作是在 poll()方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检 查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。<br>    由于自动提交是延时提交，如果服务异常导致位移不能提交的话，可能会导致重复消费。如果消费端只是将数据存入内存，并提交位移，可能会导致消息丢失。</p>
<h3 id="同步手动提交"><a href="#同步手动提交" class="headerlink" title="同步手动提交"></a>同步手动提交</h3><p>通过调用 consumer.commitSync() 来进行同步提交，不传递任何参数时提交的是当前轮询的最大偏移量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">while (true) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS));</span><br><span class="line">    for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(record);</span><br><span class="line">    &#125;</span><br><span class="line">    /*同步提交*/</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果某个提交失败，同步提交还会进行重试，这可以保证数据能够最大限度提交成功，但是同时也会降低程序的吞吐量。基于这个原因，Kafka 还提供了异步提交的 API。</p>
<h3 id="异步手动提交"><a href="#异步手动提交" class="headerlink" title="异步手动提交"></a>异步手动提交</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">while (true) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS));</span><br><span class="line">    for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(record);</span><br><span class="line">    &#125;</span><br><span class="line">    /*异步提交并定义回调*/</span><br><span class="line">    consumer.commitAsync(new OffsetCommitCallback() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123;</span><br><span class="line">          if (exception != null) &#123;</span><br><span class="line">             System.out.println(&quot;错误处理&quot;);</span><br><span class="line">             offsets.forEach((x, y) -&gt; System.out.printf(&quot;topic = %s,partition = %d, offset = %s \n&quot;,</span><br><span class="line">                                                            x.topic(), x.partition(), y.offset()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="同步加异步提交"><a href="#同步加异步提交" class="headerlink" title="同步加异步提交"></a>同步加异步提交</h3><p>在正常的轮询中使用异步提交来保证吞吐量，但是因为在最后即将要关闭消费者了，所以此时需要用同步提交来保证最大限度的提交成功。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    while (true) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS));</span><br><span class="line">        for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">            System.out.println(record);</span><br><span class="line">        &#125;</span><br><span class="line">        // 异步提交</span><br><span class="line">        consumer.commitAsync();</span><br><span class="line">    &#125;</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        // 因为即将要关闭消费者，所以要用同步提交保证提交成功</span><br><span class="line">        consumer.commitSync();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        consumer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="位移消费"><a href="#位移消费" class="headerlink" title="位移消费"></a>位移消费</h2><p>当消费者找不到自己的消费记录时，会根据参数auto.offset.reset来决定从何处消费。<br>auto.offset.reset有 earliest,latest,none</p>
<p>也可以通过seek指定分区的消费offset。<br><code>KafkaConsumer.seek()</code><br><code>public void seek(TopicPartition partition , long offset)</code><br>seek需要指定具体的offset，但是通常我们生产中更多的是从某个时间段开始消费。提供了OffsetsForTimes()方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsetsForTimes(Map&lt;TopicPartition, Long&gt; timestampsToSearch)</span><br><span class="line">public Map&lt;TopicPartition , OffsetAndTimestamp&gt;)</span><br><span class="line">offsetsForTimes(Map&lt;TopicPartitioη, Long&gt; timestampsToSearch,</span><br><span class="line">Duration timeout)</span><br></pre></td></tr></table></figure>
<p><img src="/media/15829725380731.jpg" alt="-w633"></p>
<h2 id="再均衡"><a href="#再均衡" class="headerlink" title="再均衡"></a>再均衡</h2><p>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者<br>再均衡发生期间，消费组内的消费者是无法读取消息的，消费者当前的状态也会丢失。</p>
<p>再均衡监昕器ConsumerRebalanceListener接口<br><code>void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions)</code>再均衡开始之前和消费者停止读取消息之后被调用。可以通过这个回调方法来处理消费位移的提交，以此来避免一些不必要的重复消费现象的发生<br><code>void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions</code>这个方法会在重新分配分区之后和消费者开始读取消费之前被调用。</p>
<p>可以在再均衡前执行一些操作：比如提交已经处理但是尚未提交的偏移量，关闭数据库连接等。此时可以在订阅主题时候，调用 subscribe 的重载方法传入自定义的分区再均衡监听器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">consumer.subscribe(Collections.singletonList(topic), new ConsumerRebalanceListener() &#123;</span><br><span class="line">    /*该方法会在消费者停止读取消息之后，再均衡开始之前就调用*/</span><br><span class="line">    @Override</span><br><span class="line">    public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123;</span><br><span class="line">        System.out.println(&quot;再均衡即将触发&quot;);</span><br><span class="line">        // 提交已经处理的偏移量</span><br><span class="line">        consumer.commitSync(offsets);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /*该方法会在重新分配分区之后，消费者开始读取消息之前被调用*/</span><br><span class="line">    @Override</span><br><span class="line">    public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">    while (true) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS));</span><br><span class="line">        for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">            System.out.println(record);</span><br><span class="line">            TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition());</span><br><span class="line">            OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(record.offset() + 1, &quot;no metaData&quot;);</span><br><span class="line">            /*TopicPartition 重写过 hashCode 和 equals 方法，所以能够保证同一主题和分区的实例不会被重复添加*/</span><br><span class="line">            offsets.put(topicPartition, offsetAndMetadata);</span><br><span class="line">        &#125;</span><br><span class="line">        consumer.commitAsync(offsets, null);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h2><p>org.apache.kafka.clients.consumer.Consumerlnterceptor接口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public ConsumerRecords&lt;K, V&gt; onConsume(ConsumerRecords&lt;K, V&gt; records); </span><br><span class="line">public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets);</span><br><span class="line">public void close();</span><br></pre></td></tr></table></figure></p>
<p>poll()方法返回之前调用拦截器的onConsume(), 可以在此过滤部分数据。<br>KafkaConsumer会在提交完消费位移之后调用拦截器的onCommit()方法，可以使用这个方法来记录跟踪所提交的位移信息</p>
<h2 id="多线程消费"><a href="#多线程消费" class="headerlink" title="多线程消费"></a>多线程消费</h2><p>KafkaProducer是线程安全的，然而KafkaConsumer却是<strong>非线程安全</strong>的<br>KafkaConsumer中定义了一个acquire()方法 ，用来检测当前是否只有一个线程在操作，<br>KafkaConsumer 中的每个公用方法在执行所要执行的动作之前都会调用这个acquire()方法， 只有wakeup()方法是个例外</p>
<ol>
<li>一个线程对应一个KafkaConsumer 实例，我们可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数.<br><img src="/media/15829730203328.jpg" alt="-w590"></li>
</ol>
<p>优点: 每个线程可以按顺序消费各个分区中的消息。<br>缺点: 每个消费线程都要维护一个独立的TCP连接， 如果分区数和consumerThreadNum的值都很大，那么会造成不小的系统开销。</p>
<ol start="2">
<li>多个消费线程同时消费同一个分区 ，这个通过assign()、seek()等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力,不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂.(不推荐）</li>
<li>将处理消息模块改成多线程的实现方式<br><img src="/media/15829730717962.jpg" alt="-w524"></li>
</ol>
<p>优点：减少 TCP 连接对系统资源的消耗，<br>缺点：对于消息的顺序处理就比较困难了，位移指针提交会增加消息重复或丢失的风险(可采用共享offset滑动窗口)</p>
<h2 id="重要消费者参数"><a href="#重要消费者参数" class="headerlink" title="重要消费者参数"></a>重要消费者参数</h2><ol>
<li>fetch.min.bytes<br> Consumer 在一次拉取请求(调用 poll()方法)中能从 Kafka 中拉取的最小数据量，默认值为 1 (B)，适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟。</li>
<li>fetch.max.bytes<br> 它用来配置 Consumer在一次拉取请求中从 Kafka 中拉取的最大数据量，默认值为 52428800B（50MB）。</li>
<li>fetch.max.wait.ms<br> 参数用于指定 Kafka 的等待时间，默认值为 500 (ms）</li>
<li>max.patition.fetch.bytes<br> 从每个分区里返回给 Consumer的最大数据量，默认值为 1048576B(1MB),与<br>fetch.max.bytes参数相似，前者用来限制一次拉取中每个分区的消息大小，而后者用来限制一次拉取中整体消息的大小。</li>
<li>max.poll.records<br> 一次拉取请求中拉取的最大消息数，默认值为 500 (条)。</li>
<li>connections.max.idle.ms<br> 多久之后关闭限制的连接，默认值是 540000 (ms)，即 9 分钟。</li>
<li>exclude.internal.topics</li>
<li>receive.buffer.bytes<br> 这个参数用来设置 Socket 接收消息缓冲区(SO_RECBUF的大小，默认值为 65536B (64KB),如果设置为-1，则使用操作系统的默认值。如果Consumer与Kafka处于不同的机房， 则可以适当调大这个参数值。</li>
<li>send.buffer.bytes<br>  Socket发送消息缓冲区(SO_SNDBUF)的大小，默认值为 131072B(128KB)</li>
<li>request.timeout.ms<br>Consumer 等待请求响应的最长时间，默认值为 30000 (ms)。</li>
<li>metadata.max.age.ms<br>元数据的过期时间，默认值为 300000 (ms)，即 5 分钟。如果元数据在 此参数所限定的时间范围内没有进行更新，则会被强制更新</li>
<li>reconnect.backoff.ms<br>这个参数用来配置尝试重新连接指定主机之前的等待时间(也称为退避时间)，避免频繁地连接主机，默认值为 50 (ms)。这种机制适用于消费者向 broker 发送的所有请求。</li>
<li>retry.backoff.ms<br>这个参数用来配置尝试重新发送失败的请求到指定的主题分区之前的等待(退避)时间，<br>避免在某些故障情况下频繁地重复发送，默认值为 100 (ms)。</li>
<li>isolation.level</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://juejin.im/post/5d8593946fb9a06b0703f9c3" target="_blank" rel="noopener"> Kafka 消费者详解 </a><br><a href="https://blog.csdn.net/qq_40378034/article/details/90416260" target="_blank" rel="noopener">https://blog.csdn.net/qq_40378034/article/details/90416260</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/KaKfa生产者/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Kafka/KaKfa生产者/" itemprop="url">kafka生产者</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-28T13:00:00+08:00">
                2020-02-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h1><h2 id="生产者发送消息的简单过程"><a href="#生产者发送消息的简单过程" class="headerlink" title="生产者发送消息的简单过程"></a>生产者发送消息的简单过程</h2><p>Kafka会将发送消息包装为ProducerRecord对象，ProducerRecord 对象包含了目标主题和要发送的内容，同时还可以指定键和分区。在发送 ProducerRecord 对象前，生产者会先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。<br>接下来，数据会经过拦截器、序列化器和分区器。如果之前已经在ProducerRecord对象里指定了分区，那么分区器就不会再做任何事情。如果没有指定分区，分区器会根据ProducerRecord对象的键来选择一个分区，紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。有一个独立的线程负责把这些记录批次发送到相应的 broke上。<br>服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka，就返回一个 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，如果达到指定的重试次数后还没有成功，则直接抛出异常，不再重试。</p>
<p><img src="/media/15828633731922.jpg" alt=""></p>
<h2 id="创建生产者"><a href="#创建生产者" class="headerlink" title="创建生产者"></a>创建生产者</h2><h3 id="maven依赖："><a href="#maven依赖：" class="headerlink" title="maven依赖："></a>maven依赖：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h3 id="创建生产者-1"><a href="#创建生产者-1" class="headerlink" title="创建生产者"></a>创建生产者</h3><p>对于KafkaProducer而言，它是线程安全的，可以在多线程的环境中复用它。<br>创建 Kafka 生产者时，以下三个属性是必须指定的：</p>
<ul>
<li>bootstrap.servers: 指定broker的地址清单，清单里不需要包含所有的broker地址，生产者会从给定的broker里查找broker的信息。</li>
<li>key.serializer: 指定键的序列化器；</li>
<li>value.serializer: 指定值的序列化器。</li>
</ul>
<p>简单代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleProducer &#123;</span><br><span class="line">    public static final String brokerList = &apos;localhost:9092&apos;</span><br><span class="line">    public static final String topic = &apos;topic-demo&apos;</span><br><span class="line">    </span><br><span class="line">    public static Properties initConfig()&#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, brokerList);</span><br><span class="line">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;client.id&quot;, &quot;producer.client.id.demo&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Properties props = initConfig();        </span><br><span class="line">        /*创建生产者*/</span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello&quot;);</span><br><span class="line">        try&#123;</span><br><span class="line">            /* 发送消息*/</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        /*关闭生产者*/</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="消息发送"><a href="#消息发送" class="headerlink" title="消息发送"></a>消息发送</h2><p>上面的示例程序调用了 send 方法发送消息后没有做任何操作，在这种情况下，我们没有办法知道消息发送的结果。想要知道消息发送的结果，可以使用同步发送或者异步发送来实现。</p>
<h3 id="发后即忘"><a href="#发后即忘" class="headerlink" title="发后即忘"></a>发后即忘</h3><p>上述代码直接调用send()就是发后即忘， 不关心消息是否发送失败或成功。此种发送消息方式效率最高，但是可靠性也是最低的。</p>
<h3 id="同步发送"><a href="#同步发送" class="headerlink" title="同步发送"></a>同步发送</h3><p>在调用 send 方法后可以接着调用get() 方法，send 方法的返回值是一个 Future<recordmetadata>对象，RecordMetadata 里面包含了发送消息的主题、分区、偏移量等信息。改写后的代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello&quot;);</span><br><span class="line">    /*同步发送消息*/</span><br><span class="line">    RecordMetadata metadata = producer.send(record).get();</span><br><span class="line">    System.out.printf(&quot;topic=%s, partition=%d, offset=%s \n&quot;,</span><br><span class="line">            metadata.topic(), metadata.partition(), metadata.offset());</span><br><span class="line">&#125; catch (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></recordmetadata></p>
<p>此发送方式可靠性高，但是发送性能低。</p>
<h3 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h3><p>通常我们并不关心发送成功的情况，更多关注的是失败的情况，因此 Kafka 提供了异步发送和回调函数。 代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello&quot;);</span><br><span class="line">/*异步发送消息，并监听回调*/</span><br><span class="line">producer.send(record, new Callback() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void onCompletion(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">        if (exception != null) &#123;</span><br><span class="line">            System.out.println(&quot;进行异常处理&quot;);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            System.out.printf(&quot;topic=%s, partition=%d, offset=%s \n&quot;,</span><br><span class="line">                    metadata.topic(), metadata.partition(), metadata.offset());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h3 id="消息发送重试"><a href="#消息发送重试" class="headerlink" title="消息发送重试"></a>消息发送重试</h3><p>KafkaProducer中一般会发生两种类型的异常: 可重试异常和不可重试的异常。常见的可重试异常有网络异常，副本异常等，可在一定次数的重试后发送成功。但是如发送消息过大这类不可重试的异常则重试解决不了问题。<br>对于可重试的异常，如果配置了retries参数，则在规定次数内发送成功，则不会抛出异常。不可重试的异常则直接抛出。</p>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>接口: org.apache.kafka.common.serialization.Serializer<br>三个方法：<br>public void configure (Map&lt;String,?&gt; configs , boolean isKey)<br>public byte[] serialize(String topic, T data)<br>public void close()<br>configure()方法用来配置当前类，serialize()方法用来执行序列化操作。而close()方法用来关 闭当前的序列化器，一般情况下 close()是一个空方法， 如果实现了此方法，则必须确保此方法的幕等性，因为这个方法很可能会被 KafkaProducer调用多次。</p>
<h2 id="分区器"><a href="#分区器" class="headerlink" title="分区器"></a>分区器</h2><p>如果消息 ProducerRecord中没有指定partition字段，那么就需要依赖分区器， 根据 key, 这个字段来计算partition的值。分区器的作用就是为消息分配分区。<br>默认方法:<br>    org.apache.kafka.clients.producer.intemals.DefaultPartitioner<br>接口:<br>    org.apache.kafka.clients.producer.Partitioner<br>方法:</p>
<ul>
<li>public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);</li>
<li>public void close();</li>
</ul>
<p>默认是如果key不为null，那么默认的分区器会对key进行哈希，有相同key的消息会被写入同一个分区。如果key为null，那么消息将会以轮询的方式发往主题内的各个可用分区。<br>注意：不为null，是所有分区的一个，为null是可用分区的一个</p>
<h2 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h2><p>生产者拦截器既可以用来在消息发送前做一些准备工作， 比如按照某个规则过滤不符合要求的消息、修改消息的内容等， 也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。<br>接口: org.apache.kafka.clients.producer.Producerlnterceptor</p>
<ul>
<li>public ProducerRecord&lt;K, V&gt; onSend (ProducerRecord&lt;K, V&gt; record);</li>
<li>public void onAcknowledgement(RecordMetadata metadata, Exception exception ); </li>
<li>public void close();</li>
</ul>
<p>KafkaProducer在将消息序列化和计算分区之前会调用生产者拦截器的onSend()方法<br>KafkaProducer会在消息被应答(Acknowledgement)之前或消息发送失败时调用生产者拦截器的 onAcknowledgement()方法，优先于用户设定的Callback之前执行。这个方法运行在Producer 的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好，否则会影响消息的发送速度。<br>    还可以指定多个拦截器以形成拦截链。拦截链会按照 interceptor.classes 参数配置的拦截器的顺序来一一执行</p>
<h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><p><img src="/media/15828787180589.jpg" alt="-w749"><br>整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和Sender线程 (发送线程)。在主线程中由 KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器(RecordAccumulator，（双端队列Deque）也称为消息收集器)中。 Sender线程负责从 RecordAccumulator中获取消息并将其发送到Kafka中。</p>
<h3 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h3><p>RecordAccumulator主要用来缓存消息 以便Sender线程可以批量发送，进而减少网络传输 的资源消耗以提升性能。 RecordAccumulator缓存的大小可以通过参数 buffer.memory 配置，默认值为32M。<br>   生产者发送消息速度超过发送到服务器的速度时，会导致生产者空间不足。KafkaProducer的send()方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的配置，此参数的默认值为 60000, 即 60 秒 。<br>   在发送之前需要创建一块内存区域来保存对应的消息，RecordAccumulator的内部还有一个 BufferPool, 它主要用来实现 ByteBuffer的复用，以实现缓存的高效利用。 batch.size 参数来指定，默认值为 16384B，即 16KB<br>   ProducerBatch的大小和 batch.size参数也有着密切的关系。当一条消息(ProducerRecord) 流入 RecordAccumulator 时，会先寻找与消息分区所对应的双端队列(如果没有则新建)，再从 这个双端队列的尾部获取一个 ProducerBatch (如果没有则新建)，查看 ProducerBatch 中是否还可以写入这个ProducerRecord，如果可以则 写入，如果不可 以则需要创建一个新 的 ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过 batch.size 参数的大小，如果不超过，那么就以 batch.size参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过 BufferPool的管理来进行复用;如果超过，那么就以评估的大小来 创建 ProducerBatch，这段内存区域不会被复用。</p>
<p>   Sender 从 RecordAccumulator中获取缓存的消息之后，会进一步将原本&lt;分区， Deque<producerbatch>&gt;的保存形式转变成&lt;Node, List<producerbatch>的形式，其中 Node表示Kafka 集群的broker节点。</producerbatch></producerbatch></p>
<h3 id="InFlightRequests"><a href="#InFlightRequests" class="headerlink" title="InFlightRequests"></a>InFlightRequests</h3><p>请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象形式为Map&lt;NodeId, Deque<request>&gt;，它的主要作用是缓存了已经发出去但还没有收到响应的请求。与此同时, InFlightRequests还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接(也就是客户端与Node之间的连接)最多缓存的请求数。这个配置参数为 max.in.flight.requests.per.connection，默认值为5，即每个连接最多只能缓存 5 个未响应的请求，超过该数值之后就不能再向这个连接发送更多的请求了，除非有缓存的请求收到了响应(Response)。<br>   InFlightRequests 还可以获得 leastLoadedNode，即所有Node中负载最小的那一个。这里的负载最小是通过每个Node在InFlightRequests中还未确认的请求决定的，未确认的请求越多则认为负载越大。<br>   <img src="/media/15828787308307.jpg" alt="-w357"><br>    当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 metadata.max.age.ms时间没有更新元数据都会引起元数据的更新操作 。客户端参数 metadata.max.age.ms的默认值为 300000，即5分钟。元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出leastLoadedNode, 然后向这个Node发送 MetadataRequest请求来获取具体的元数据信息。这个更新操作是由 Sender线程发起的，在创建完MetadataRequest之后同样会存入InFlightRequests之后的步骤就和发送消息时的类似。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里的数据同步通过 synchronized 和 final 关键字来保障。</request></p>
<h3 id="重要参数"><a href="#重要参数" class="headerlink" title="重要参数"></a>重要参数</h3><ol>
<li>acks<br>分区中必须要有多少个副本收到这条消息才会认为这条消息是成功写入的。<br>acks参数有3种类型的值(都是字符串类型)。<br>acks = 1。默认值即为1, 只要分区的leader副本成功写入消息就算成功<br>acks = 0。不需要任何回应，吞吐量最大<br>acks =-1 或 acks =all。 ISR中的所有副本都成功写入后才算成功。</li>
<li>max.request.size<br>客户端能发送的消息的最大值，默认值为 1048576B，即 1MB。</li>
<li>retries 和 retry.backoff.ms<br>retries 参数用来配置生产者重试的次数，默认值为0<br>retry.backoff.ms: 两次重试之间的时间间隔有关，这个参数的默认值为100</li>
</ol>
<p>Kafka 可以保证同一个分区中的消息是有序的。对于某些应用来说，顺序性非常重要，比如 MySQL的binlog传输，如果出现错误就会造成非常严重的后果。如果将 acks 参数配置为非零值，并且 max.in.flight.requests.per.connection 参数配置为大于1的值，那么就会出现错序的现象: 如果第一批次消息写入失败，而第二批次消息写入成功，那么生产者会重试发送第一批次的消息，此时如果第一批次的消息写入成功，那么这两个批次的消息就出现了错序。一般而言，在需要保证消息顺序的场合建议把参数 max.in.flight.requests.per.connection 配置为1，而不是把acks 配置为0， 不过这样也会影响整体的吞吐。</p>
<ol start="4">
<li>compression.type<br> 消息的压缩方式，默认值为”none”, 该参数还可以配置为”gzip”,”snappy”和”lz4”</li>
<li>connections.max.idle.ms<br> 指定在多久之后关闭限制的连接，默认值是 540000 (ms),即 9 分钟。</li>
<li>linger.ms<br> 默认值为0, 生产者客户端会在 ProducerBatch被填满或等待时间超过linger.ms值时发出去。</li>
<li>receive.buffer.bytes<br> 这个参数用来设置 Socket 接收消息缓冲区(SO_RECBUF)的大小，默认值为 32768(B)， 即32kb。如果设置为一1，则使用操作系统的默认值。如果 Producer与 Kafka处于不同的机房， 则可以适地调大这个参数值。</li>
<li>send.buffer.bytes<br> 默认值为131072(B), 128KB</li>
<li>request.timeout.ms<br>  Producer等待请求响应的最长时间，默认值为30000 (ms)。请求超时之后可以选择进行重试 。注意这个参数需要比broker端参数replica.lag.time.max.ms的值要大，这样 可以减少因客户端重试而引起的消息重复的概率。</li>
<li>其他<br><img src="/media/15828801094738.jpg" alt="-w709"><br><img src="/media/15828801200328.jpg" alt="-w678"></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Liusuifeng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liusuifeng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
