<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="kafka,">










<meta name="description" content="kafka客户端深入分区分配策略Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略 RangeAssignor分配策略RangeAssignor分配策略的原理">
<meta name="keywords" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka客户端深入">
<meta property="og:url" content="https://liusuifeng1994.github.io/Kafka/Kafka客户端深入/index.html">
<meta property="og:site_name" content="Liusuifeng&#39;s Blog">
<meta property="og:description" content="kafka客户端深入分区分配策略Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略 RangeAssignor分配策略RangeAssignor分配策略的原理">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843273229031.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843273748546.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843277236078.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843277377271.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843278063361.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843282888371.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843283068631.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843283944359.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843284515676.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843284983945.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843285202365.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843286447750.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15843287094227.jpg">
<meta property="og:updated_time" content="2020-03-16T03:19:21.970Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka客户端深入">
<meta name="twitter:description" content="kafka客户端深入分区分配策略Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略 RangeAssignor分配策略RangeAssignor分配策略的原理">
<meta name="twitter:image" content="https://liusuifeng1994.github.io/media/15843273229031.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://liusuifeng1994.github.io/Kafka/Kafka客户端深入/">





  <title>kafka客户端深入 | Liusuifeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liusuifeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kafka客户端深入/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">kafka客户端深入</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-17T13:00:00+08:00">
                2020-03-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="kafka客户端深入"><a href="#kafka客户端深入" class="headerlink" title="kafka客户端深入"></a>kafka客户端深入</h1><h2 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h2><p>Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略</p>
<h3 id="RangeAssignor分配策略"><a href="#RangeAssignor分配策略" class="headerlink" title="RangeAssignor分配策略"></a>RangeAssignor分配策略</h3><p>RangeAssignor分配策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区</p>
<p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区<br>假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有4个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t0p3、t1p0、t1p1、t1p2、t1p3。最终的分配结果为：<br>消费者C0：t0p0、t0p1、t1p0、t1p1<br>消费者C1：t0p2、t0p3、t1p2、t1p3</p>
<p>假设2个主题都只有3个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：<br>消费者C0：t0p0、t0p1、t1p0、t1p1<br>消费者C1：t0p2、t1p2</p>
<h3 id="RoundRobinAssignor分配策略"><a href="#RoundRobinAssignor分配策略" class="headerlink" title="RoundRobinAssignor分配策略"></a>RoundRobinAssignor分配策略</h3><p>RoundRobinAssignor分配策略的原理是将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区一次分配给每个向消费者。RoundRobinAssignor分配策略对应的partition.assignment.strategy参数值为org.apache.kafka.clients.consumer.RoundRobinAssignor</p>
<p>如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor分配策略的分区分配会是均匀的</p>
<p>假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么订阅的所有分区可以表示为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终分配结果为：<br>消费者C0：t0p0、t0p2、t1p1<br>消费者C1：t0p1、t1p0、t1p2</p>
<p>如果同一个消费组内的消费者订阅的信息不是相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能导致分区分配得不均匀<br>假设消费组内有3个消费者（C0、C1和C2），它们共订阅了3个主题（t0、t1和t2），这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区，消费者C0订阅了主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果是：<br>消费者C0：t0p0<br>消费者C1：t1p0<br>消费者C2：t1p1、t2p0、t2p1、t2p2</p>
<h3 id="StickyAssignor分配策略"><a href="#StickyAssignor分配策略" class="headerlink" title="StickyAssignor分配策略"></a>StickyAssignor分配策略</h3><p>引入这个策略主要有两个目的：<br>    分区的分配要尽可能均匀<br>    分区的分配尽可能与上次分配的保持相同<br>当两者发生冲突时，第一个目标优先于第二个目标</p>
<p>假设消费组内有3个消费者（C0、C1和C2），它们都订阅了4个主题（t0、t1、t2、t3），并且每个主题有2个分区。也就是说，整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下：<br>消费者C0：t0p0、t1p1、t3p0<br>消费者C1：t0p1、t2p0、t3p1<br>消费者C2：t1p0、t2p1</p>
<p>和RoundRobinAssignor分配策略所分配的结果相同，假设此时消费者C1脱离了消费组，那么消费组就会执行再均衡操作， 进而消费分区会重新分配。如果采用RoundRobinAssignor分配策略，那么此时的分配结果如下：<br>消费者C0：t0p0、t1p0、t2p0、t3p0<br>消费者C2：t0p1、t1p1、t2p1、t3p1</p>
<p>RoundRobinAssignor分配策略会按照消费者C0和C2进行重新轮询分配。如果使用的是StickyAssignor分配策略，分配结果为：<br>消费者C0：t0p0、t1p1、t3p0、t2p0<br>消费者C2：t1p0、t2p1、t0p1、t3p1</p>
<p>分配结果中保留了上一次分配中对消费者C0和C2的所有分配结果，并将原来消费者C1的负担分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡</p>
<p>StickyAssignor分配策略尽可能地让前后两次分配相同，进而减少系统资源的损耗及其他异常情况的发生<br>假设消费组内有3个消费者（C0、C1和C2），它们共订阅了3个主题（t0、t1和t2），这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区，消费者C0订阅了主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果是<br>消费者C0：t0p0<br>消费者C1：t1p0、t1p1<br>消费者C2：t2p0、t2p1、t2p2</p>
<h3 id="自定义分区分配策略"><a href="#自定义分区分配策略" class="headerlink" title="自定义分区分配策略"></a>自定义分区分配策略</h3><p>自定义的分配策略必须要实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口</p>
<p>PartitionAssignor接口中定义了两个内部类：Subscription和Assignment<br>Subscription类用来表示消费者的订阅信息，类中有两个属性：topics和userData，分别表示消费者的订阅主题列表和用户自定义信息<br>Assignment类用来表示分配结果信息，类中也有两个属性：partitions和userData，分别表示所分配到的分区集合和用户自定义的数据<br>onAssignment()方法是在每个消费者收到消费组leader分配结果时的回调函数<br>name()方法用来提供分配策略的名称，自定义的分配策略要注意命名不要与已存在的分配策略发生冲突<br>真正的分区分配方案的实现是在assign()方法中，方法中的参数metadata表示集群的元数据信息，而subscriptions表示消费组内各个消费者成员的订阅信息，最终方法返回各个消费者的分配信息</p>
<h2 id="消费者协调器和组协调器"><a href="#消费者协调器和组协调器" class="headerlink" title="消费者协调器和组协调器"></a>消费者协调器和组协调器</h2><h3 id="再均衡的原理"><a href="#再均衡的原理" class="headerlink" title="再均衡的原理"></a>再均衡的原理</h3><p>消费者客户端将全部消费者组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，GroupCoordinator是Kafka服务端中用于管理消费组的组件。而消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。<br>ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括分区分配的工作也是在再均衡期间完成的</p>
<p>当有消费者加入消费组时，消费者、消费组及组协调器之间会经历一下几个阶段<br><strong>第一阶段（FIND_COORDINATOR）</strong><br>消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接。如果消费者已经保存了与消费组对应的GroupCoordinator节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则，就需要向集群中的负载最小的节点发送FindCoordinatorRequest请求来查找对应的GroupCoordinator</p>
<p>FindCoordinatorRequest请求体中只有两个域：coordinator_key和coordinator_type。coordinator_key是消费组的名称，即groupId，coordinator_type置为0<br><img src="/media/15843273229031.jpg" alt="-w833"></p>
<p>Kafka在收到FindCoordinatorRequest请求之后，会根据coordinator_key查找对应的GroupCoordinator节点，找到对应的GroupCoordinator则会返回其相应的nod_id、host和port信息</p>
<p><strong>第二阶段（JOIN_GROUP）</strong><br>在成功找到消费组所对应的GroupCoordinator之后就进入加入消费组的阶段，在此阶段的消费者会向GroupCoordinator发送JoinGroupRequest请求，并处理响应<br><img src="/media/15843273748546.jpg" alt="-w822"></p>
<p>joinGroupRequest的结构包含多个域：</p>
<ul>
<li>group_id就是消费组的id</li>
<li>session_timeout对应消费端参数session.timeout.ms，默认值为10000，即10秒。GroupCoordinator超过session_timeout指定的时间内没有收到心跳报文则认为此消费者已经下线</li>
<li>rebalance_timeout对应消费端参数max.poll.interval.ms，默认值为300000，即5分钟。表示当下消费组再均衡的时候，GroupCoordinator等待各个消费者重新加入的最长等待时间</li>
<li>member_id表示GroupCoordinator分配给消费者的id标识。消费者第一次发送JoinGroupRequest请求的时候此字段设置为null</li>
<li>protocol_type表示消费组实现的协议，对于此消费者而言此字段值为consumer</li>
</ul>
<p>JoinGroupRequest中的group_protocols域为数组类型，其中可以囊括多个分区分配策略，主要取决于消费者客户端参数partition.assignment.strategy的配置。如果配置了多种策略，那么JoinGroupRequest中就会包含多个protocol_name和protocol_metadata</p>
<p>消费者在发送JoinGroupRequest请求之后会阻塞等待Kafka服务端的响应。服务端在收到JoinGroupRequest请求后会交由GroupCoordinator来进行处理。GroupCoordinator首先会对JoinGroupRequest请求做合法性校验。如果消费者是第一次请求加入消费组，那么JoinGroupRequest请求中的member_id值为null，此时组协调器负责为此消费者生成一个member_id（clientId+”-“+UUID）</p>
<p>1）选举消费组的leader<br>GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader。如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader。如果某一时刻leader消费者退出了消费组，那么会重新选举一个新的leader。在GroupCoordinator中消费者的信息是以HashMap的形式存储的，其中key为消费者的member_id，而value是消费者相关的元数据信息。leaderId表示leader消费者的member_id，它的取值为HashMap中的第一个键值对的key</p>
<p>2）选举分区分配策略<br>分区分配的选举并非由leader消费者决定，而是根据消费组内的各个消费者投票来决定<br>A.收集各个消费者支持的所有分配策略，组成候选集candidates<br>B.每个消费者从候选集candidates中找出第一个自身支持的策略，为这个策略投上一票<br>C.计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略</p>
<p>消费者所支持的分配策略是partition.assignment.strategy参数配置的策略<br>在此之后，Kafka服务端就要发送JoinGroupResponse响应给各个消费者，JoinGroupResponse中包含GroupCoordinator中投票选举出的分配策略的信息。并且，只有leader消费者的JoinGroupResponse中包含各个消费者的订阅信息。Kafka把分区策略的具体分配交还给客户端，自身并不参与具体的分配细节，这样即使以后分区分配的策略发生了变更，只需要重启消费端的应用即可，而不需要重启服务端</p>
<p><img src="/media/15843277236078.jpg" alt="-w469"></p>
<p><img src="/media/15843277377271.jpg" alt="-w453"></p>
<p><strong>第三阶段（SYNC_GROUP）</strong><br>在第三个阶段，也就是同步阶段，各个消费者GroupCoordinator发送SyncGroupRequest请求来同步分配方案<br><img src="/media/15843278063361.jpg" alt="-w469"></p>
<p>GroupCoordinator会先对SyncGroupRequest请求做合法性校验，在此之后会将从leader消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送SyncGroupResponse给各个消费者各自所属的分配方案</p>
<p>当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment()方法。随后再调用ConsumerRebalanceListener中的onPartitionsAssigned()方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartBeatRequest来确定彼此在线</p>
<p><strong>第四阶段（HEARTBEAT）</strong><br>消费组中的所有消费者处于正常工作状态。在正式消费之前，消费者还需要确定拉取消息的起始位置。假设之前已经将最后的消费位移提交到了GroupCoordinator，并且GroupCoordinator将其保存到了Kafka内部的__consumer_offsets主题中，此时消费者可以通过OffsetFetchRequest请求获取上次提交的消费位移并从此处继续消费</p>
<p>消费者通过向GroupCoordinator发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区中的消息。心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话被判定为过期，GroupCoordinator也会认为这个消费者已经死亡，就会触发一次再均衡行为</p>
<h2 id="事务与幂等"><a href="#事务与幂等" class="headerlink" title="事务与幂等"></a>事务与幂等</h2><h3 id="消息传输保障"><a href="#消息传输保障" class="headerlink" title="消息传输保障"></a>消息传输保障</h3><p>消息中间件的消息传输保障有3个层级：</p>
<ul>
<li>at most once：至多一次。消息可能会丢失，但绝对不会重复传输</li>
<li>at least once：最少一次。消息绝不会丢失，但可能会重复传输</li>
<li>exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次</li>
</ul>
<h3 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h3><p>幂等是指对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka的幂等性功能之后就可以避免这种情况</p>
<p>开启幂等性功能需要显示地将生产者客户端参数enable.idempotence设置为true即可（这个参数默认值为false）<br><code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);</code></p>
<p>如果要确保幂等性功能正常，需要确保生产者客户端的retries、acks、max.in.flight.requests.per.connection这几个参数不被配置错。在使用幂等性功能的时候，用户完全不需要配置这几个参数</p>
<p>如果用户显示指定了retries参数，那么这个参数的值必须大于0，如果没有显示指定retries参数，那么KafkaProducer会将它置为Integer.MAX_VALUE。同时还要保证max.in.flight.requests.per.connection（限制每个连接最多缓存的请求数）参数的值不能大于5，acks参数的值为-1</p>
<p>为了实现生产者的幂等性，Kafka为此引入了producer id（PID）和序列号这两个概念。每个新的生产者实例在初始化的时候都会被分配一个PID，这个PID对用户而言是完全透明的。对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将&lt;PID，分区&gt;对应的序列号的值加1</p>
<p>broker端会在内存中为每一对&lt;PID，分区&gt;维护一个序列号。对于收到的每一条消息，只有当它的序列号的值比broker端中维护的对应的序列号的值大1（即SN_new=SN_old+1）时，broker才会接收它。如果SN_new&lt;SN_old+1，那么说明消息被重复写入，broker可以直接将其丢弃。如果SN_new&gt;SN_old+1，那么说明中间有数据尚未写入，出现了乱序，可能有消息丢失，对应的生产者会抛出OutOfOrderSequenceException</p>
<p>引入序列号来实现幂等性只是针对每一对&lt;PID，分区&gt;而言的，也就是说，Kafka的幂等性只能保证单个生产者会话中单分区的幂等</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务可以保证对多个分区写入操作的原子性。Kafka中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败，即使该生产或消费会跨多个分区</p>
<p>为了实现事务，应用程序必须提供唯一的transactionId，这个transactionId通过客户端参数transactional.id来显示指定<br><code>props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;transactionId&quot;);</code></p>
<p>事务要求生产者开启幂等特性，因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将enable.idempotence设置为true（如果未显示指定，则KafkaProducer默认会将它的值设置为true）</p>
<p>transactionId与PID一一对应，两者之间所不同的是transactionId由用户显示指定，而PID是由Kafka内部分配的。另外，为了保证新的生产者启动后具有相同transactionId的旧生产者能够立即失效，每个生产者通过transactionId获取PID的同时，还会获取一个单调递增的producer epoch。如果使用同一个transactionId开启两个生产者，那么前一个开启的生产者会报错</p>
<p>从生产者的角度分析，通过事务，Kafka可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复。前者表示具有相同transactionId的新生产者实例被创建且工作的时候，旧的且拥有相同transactionId的生产者实例将不再工作。后者指当某个生产者实例宕机后，新的生产者实例可以保证任何未完成的旧事物要么被提交，要么被中止，如此可以是新的生产者实例从一个正常的状态开始工作</p>
<p>从消费者的角度分析，Kafka并不能保证已提交的事务中的所有消息都能够被消费：</p>
<ul>
<li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理（相同key的消息，后写入的消息会覆盖前面写入的消息）</li>
<li>事务中消息可能分布在同一个分区的多个日志分段中，当老的日志分段被删除时，对应的消息可能会丢失</li>
<li>消费者可以通过seek()方法访问任意offset的消息，从而可能遗漏事务中的部分消息</li>
<li>消费者在消费时可能没有分配到事务内的所有分区，如此它也就不能读取事务中的所有消息</li>
</ul>
<p>KafkaProducer提供了5个与事务相关的方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//初始化事务</span><br><span class="line">void initTransactions()</span><br><span class="line">//开启事务</span><br><span class="line">void beginTransaction() throws ProducerFencedException</span><br><span class="line">//消费者在事务内的位移提交</span><br><span class="line">void sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span><br><span class="line">							  String consumerGroupId) throws ProducerFencedException</span><br><span class="line">//提交事务							  </span><br><span class="line">void commitTransaction() throws ProducerFencedException</span><br><span class="line">//中止事务</span><br><span class="line">void abortTransaction() throws ProducerFencedException</span><br></pre></td></tr></table></figure>
<p>事务发送事例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, transactionId);</span><br><span class="line">KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">producer.initTransactions();</span><br><span class="line">producer.beginTransaction();</span><br><span class="line">try &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record1 = new ProducerRecord&lt;&gt;(topic, &quot;msg1&quot;);</span><br><span class="line">    producer.send(record1);</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record2 = new ProducerRecord&lt;&gt;(topic, &quot;msg2&quot;);</span><br><span class="line">    producer.send(record2);</span><br><span class="line">    producer.commitTransaction();</span><br><span class="line">&#125; catch (ProducerFencedException e) &#123;</span><br><span class="line">    producer.abortTransaction();</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">    producer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在消费端有一个参数isolation.level，默认值为read_uncommitted，意思是说消费端应用可以消费到未提交的事务。还可以设置为read_committed，表示消费端应用只能看到提交的事务<br><img src="/media/15843282888371.jpg" alt="-w660"><br>日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是控制消息（ControlBatch）。控制消息一共有两种类型：COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止。KafkaConsumer可以通过这个控制消息来判断对应的事务是被提交了还是被中止了，然后结合参数isolation.level配置的隔离级别来决定是否将相应的消息返回给消费端应用</p>
<p>consume-transform-produce（消费-转换-生产）示例：<br><img src="/media/15843283068631.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest</span><br><span class="line">public class TransactionConsumerTransformProduceTest &#123;</span><br><span class="line">    public static final String brokerList = &quot;192.168.126.158:9092&quot;;</span><br><span class="line"></span><br><span class="line">    public Properties getConsumerProperties() &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;groupId&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Properties getProducerProperties() &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;transactionId&quot;);</span><br><span class="line">        return props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    public void consumerTransformProduceTest() &#123;</span><br><span class="line">        //初始化生产者和消费者</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(getConsumerProperties());</span><br><span class="line">        consumer.subscribe(Collections.singleton(&quot;topic-source&quot;));</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(getProducerProperties());</span><br><span class="line">        //初始化事务</span><br><span class="line">        producer.initTransactions();</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000));</span><br><span class="line">            if (!records.isEmpty()) &#123;</span><br><span class="line">                Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();</span><br><span class="line">                //开启事务</span><br><span class="line">                producer.beginTransaction();</span><br><span class="line">                try &#123;</span><br><span class="line">                    for (TopicPartition partition : records.partitions()) &#123;</span><br><span class="line">                        List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);</span><br><span class="line">                        for (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123;</span><br><span class="line">                            System.out.println(&quot;topic=&quot; + record.topic() + &quot;,partition=&quot; + record.partition() + &quot;,offset=&quot; + record.offset());</span><br><span class="line">                            System.out.println(&quot;key=&quot; + record.key() + &quot;,value=&quot; + record.value());</span><br><span class="line">                            ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;&gt;(&quot;topic-sink&quot;, record.key(), record.value());</span><br><span class="line">                            //消费-生产模型</span><br><span class="line">                            producer.send(producerRecord);</span><br><span class="line">                        &#125;</span><br><span class="line">                        long lastConsumedOffset = partitionRecords.get(partitionRecords.size() - 1).offset();</span><br><span class="line">                        offsets.put(partition, new OffsetAndMetadata(lastConsumedOffset + 1));</span><br><span class="line">                    &#125;</span><br><span class="line">                    //提交消费位移</span><br><span class="line">                    producer.sendOffsetsToTransaction(offsets, &quot;groupId&quot;);</span><br><span class="line">                    //提交事务</span><br><span class="line">                    producer.commitTransaction();</span><br><span class="line">                &#125; catch (ProducerFencedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                    producer.abortTransaction();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了实现事务的功能，Kafka引入了事务协调器（TransactionCoordinator）。每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括分派PID等都是由TransactionCoordinator来负责实施的。TransactionCoordinator会将事务状态持久化到内部主题__transaction_state中</p>
<p>以consume-transform-produce的流程为例分析Kafka事务的实现原理<br><img src="/media/15843283944359.jpg" alt="-w763"></p>
<h4 id="1）查找TransactionCoordinator"><a href="#1）查找TransactionCoordinator" class="headerlink" title="1）查找TransactionCoordinator"></a>1）查找TransactionCoordinator</h4><p>生产者向Kafka发送FindCoordinatorRequest请求，Kafka在收到FindCoordinatorRequest请求之后，会根据coordinator_key（transactionId）查找对应的TransactionCoordinator节点。如果找到，则会返回其相应的node_id、host和port信息。具体查找TransactionCoordinator的方式是根据transactionId的哈希值计算主题__transaction_state中的分区编号，找到对应的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为transactionId对应的TransactionCoordinator节点</p>
<h4 id="获取PID"><a href="#获取PID" class="headerlink" title="获取PID"></a>获取PID</h4><p><img src="/media/15843284515676.jpg" alt=""><br>在找到TransactionCoordinator节点之后，需要为当前生产者分配一个PID。凡是开启了幂等性功能的生产者都必须执行这个操作，不需要考虑该生产者是否还开启了事务。生产者获取PID的操作是通过InitProducerIdRequest请求来实现的，InitProducerIdRequest请求体结构如上图所示，其中transactional_id表示事务的transactionId，transaction_timeout_ms表示TransactionCoordinator等待事务状态更新的超时时间，通过生产者客户端参数transaction.timeout.ms配置，默认值为60000<br><img src="/media/15843284983945.jpg" alt="-w592"></p>
<p>生产者的InitProducerIdRequest请求会被发送给TransactionCoordinator。如果没开启事务特性而只开启幂等特性，那么InitProducerIdRequest请求可以发送给任意的broker。当TransactionCoordinator第一次收到包含该transactionId的InitProducerIdRequest请求时，它会把transactionId和对应的PID以消息（事务日志消息）的形式保存到主题__transaction_state中，如上图所示。这样可以保证&lt;transactionId,PID&gt;的对应关系被持久化，从而保证即使TransactionCoordinator宕机该对应关系也不会丢失</p>
<p>其中transaction_status包含Empty(0)、Ongoing（1）、PrepareCommit(2)、PrepareAbort(3)、CompleteCommit(4)、CompleteAbort(5)、Dead(6)这几种状态。在存入主题__transaction_state之前，事务日志消息同样会根据单独的transactionId来计算要发送的分区<br><img src="/media/15843285202365.jpg" alt=""></p>
<p>initProducerIdRequest对应的InitProducerIdResponse响应体结构如上图所示，除了返回PID，还会触发执行以下任务：</p>
<ul>
<li>增加该PID对应的producer_epoch。具有相同PID但producer_epoch小于该producer_epoch的其他生产者新开启的事务将被拒绝</li>
<li>恢复和终止之前的生产者未完成的事务</li>
</ul>
<h4 id="3）开启事务"><a href="#3）开启事务" class="headerlink" title="3）开启事务"></a>3）开启事务</h4><p>通过KafkaProducer的beginTransaction()方法可以开启一个事务，调用该方法后，生产者本地会标记已经开启一个新的事务，只有在生产者发送第一条消息之后TransactionCoordinator才会认为该事务已经开启</p>
<h4 id="4）Consume-Transform-Produce"><a href="#4）Consume-Transform-Produce" class="headerlink" title="4）Consume-Transform-Produce"></a>4）Consume-Transform-Produce</h4><p>这个阶段囊括了整个事务的数据处理过程</p>
<p><strong>AddPartitionsToTxnRequest</strong><br>当生产者给一个新的分区（TopicPartition）发送数据前，它需要先向TransactionCoordinator发送AddPartitionsToTxnRequest请求，这个请求会让TransactionCoordinator将&lt;transactionId,TopicPartition&gt;的对应关系存储在主题__transaction_state中，有了这个对照关系在后续的步骤中为每个分区设置COMMIT或ABORT标记<br>如果该分区是对应事务中的第一个分区，那么此时TransactionCoordinator还会启动对该事务的计时</p>
<p><strong>ProduceRequest</strong><br>生产者通过ProduceRequest请求发送消息（ProducerBatch）到用户自定义主题中，和普通消息不同的是ProducerBatch中会包含实质的PID、producer_epoch和sequence number</p>
<p><strong>AddOffsetsToTxnRequest</strong><br>通过KafkaProducer的sendOffsetsToTransaction()方法可以在一个事务批次里处理消息的消费和发送，方法中包含2个参数：Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets和String consumerGroupId。这个方法会向TransactionCoordinator节点发送AddOffsetsToTxnRequest请求。TransactionCoordinator收到这个请求之后会通过groupId来推导出在<strong>consumer_offsets中的分区，之后TransactionCoordinator会将整个分区保存在</strong>transaction_state中</p>
<p><strong>TxnOffsetCommitRequest</strong><br>这个请求也是sendOffsetsToTransaction()方法中的一部分，在处理完AddOffsetsToTxnRequest之后，生产者还会发送TxnOffsetCommitRequest请求给GroupCoordinator，从而将本次事务中包含的消费位移信息offsets存储到主题__consumer_offsets中</p>
<h4 id="5）提交或者中止事务"><a href="#5）提交或者中止事务" class="headerlink" title="5）提交或者中止事务"></a>5）提交或者中止事务</h4><p><strong>EndTxnRequest</strong><br>无论调用commitTransaction()方法还是abortTransaction()方法，生产者都会向TransactionCoordinator发送EndTxnRequest请求，以此来通知它提交事务还是中止事务<br>TransactionCoordinator在收到EndTxnRequest请求之后会执行如下操作：</p>
<ul>
<li>A.将PREPARE_COMMIT或PREPARE_ABORT消息写入主题__transaction_state</li>
<li>B.通过WriteTxnMarkersRequest请求将COMMIT或ABORT信息写入用户所使用的普通主题和__consumer_offsets</li>
<li>C.将COMPLETE_COMMIT或COMPLETE_ABORT信息写入内部主题__transaction_state</li>
</ul>
<p><strong>WriteTxnMarkersRequest</strong><br>WriteTxnMarkersRequest请求是由TransactionCoordinator发向事务中各个分区的leader节点的，当节点收到这个请求之后，会在相应的分区中写入控制消息（ControlBatch）。控制消息用来标识事务的终结，它和普通的消息一样存储在日志文件中。RecordBatch中attributes字段的第6位用来标识当前消息是否是控制消息<br><img src="/media/15843286447750.jpg" alt=""><br>attributes字段中的第5位用来标识当前消息是否处于事务中<br><img src="/media/15843287094227.jpg" alt=""><br>控制消息的key和value内部的version值都为0，key中的type表示控制类型：0表示ABORT，1表示COMMIT；value中的coordinator_epoch表示TransactionCoordinator的纪元，TransactionCoordinator切换的时候会更新其值</p>
<p><strong>写入最终的COMPLETE_COMMIT或COMPLETE_ABORT</strong><br>TransactionCoordinator将最终的COMPLETE_COMMIT或COMPLETE_ABORT信息写入主题<strong>transaction_state以表明当前事务已经结束，此时可以删除主题</strong>transaction_state中所有关于该事务的消息。由于主题__transaction_state采用的日志清理策略为日志压缩，所以这里的删除只需要将相应的消息设置为墓碑消息即可</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/kafka/" rel="tag"># kafka</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Kafka/Kafka可靠性探究/" rel="next" title="kafka可靠性探究">
                <i class="fa fa-chevron-left"></i> kafka可靠性探究
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Liusuifeng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka客户端深入"><span class="nav-number">1.</span> <span class="nav-text">kafka客户端深入</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#分区分配策略"><span class="nav-number">1.1.</span> <span class="nav-text">分区分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RangeAssignor分配策略"><span class="nav-number">1.1.1.</span> <span class="nav-text">RangeAssignor分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RoundRobinAssignor分配策略"><span class="nav-number">1.1.2.</span> <span class="nav-text">RoundRobinAssignor分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#StickyAssignor分配策略"><span class="nav-number">1.1.3.</span> <span class="nav-text">StickyAssignor分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义分区分配策略"><span class="nav-number">1.1.4.</span> <span class="nav-text">自定义分区分配策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消费者协调器和组协调器"><span class="nav-number">1.2.</span> <span class="nav-text">消费者协调器和组协调器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#再均衡的原理"><span class="nav-number">1.2.1.</span> <span class="nav-text">再均衡的原理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#事务与幂等"><span class="nav-number">1.3.</span> <span class="nav-text">事务与幂等</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#消息传输保障"><span class="nav-number">1.3.1.</span> <span class="nav-text">消息传输保障</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#幂等"><span class="nav-number">1.3.2.</span> <span class="nav-text">幂等</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#事务"><span class="nav-number">1.3.3.</span> <span class="nav-text">事务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1）查找TransactionCoordinator"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">1）查找TransactionCoordinator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#获取PID"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">获取PID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3）开启事务"><span class="nav-number">1.3.3.3.</span> <span class="nav-text">3）开启事务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4）Consume-Transform-Produce"><span class="nav-number">1.3.3.4.</span> <span class="nav-text">4）Consume-Transform-Produce</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5）提交或者中止事务"><span class="nav-number">1.3.3.5.</span> <span class="nav-text">5）提交或者中止事务</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liusuifeng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
