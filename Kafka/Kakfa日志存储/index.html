<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="kafka,">










<meta name="description" content="Kafka日志存储文件目录布局Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后修改。每个消息在发送的时候会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量  为了防止Log过大，Kafka引入了日志分段的概念，将Log切分为多个LogSegment。">
<meta name="keywords" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka日志存储">
<meta property="og:url" content="https://liusuifeng1994.github.io/Kafka/Kakfa日志存储/index.html">
<meta property="og:site_name" content="Liusuifeng&#39;s Blog">
<meta property="og:description" content="Kafka日志存储文件目录布局Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后修改。每个消息在发送的时候会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量  为了防止Log过大，Kafka引入了日志分段的概念，将Log切分为多个LogSegment。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842482454518.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842484397403.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842486953742.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842490301193.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842491423664.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842491809480.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842495802579.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842497275763.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842497677950.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842497819362.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842498132402.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842498547813.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842499994189.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842500233532.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842500526379.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842501267485.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842501563334.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842502461853.jpg">
<meta property="og:image" content="https://liusuifeng1994.github.io/media/15842502734149.jpg">
<meta property="og:updated_time" content="2020-03-15T05:33:32.709Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka日志存储">
<meta name="twitter:description" content="Kafka日志存储文件目录布局Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后修改。每个消息在发送的时候会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量  为了防止Log过大，Kafka引入了日志分段的概念，将Log切分为多个LogSegment。">
<meta name="twitter:image" content="https://liusuifeng1994.github.io/media/15842482454518.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://liusuifeng1994.github.io/Kafka/Kakfa日志存储/">





  <title>kafka日志存储 | Liusuifeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liusuifeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liusuifeng1994.github.io/Kafka/Kakfa日志存储/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liusuifeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liusuifeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">kafka日志存储</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-15T13:00:00+08:00">
                2020-03-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Kafka日志存储"><a href="#Kafka日志存储" class="headerlink" title="Kafka日志存储"></a>Kafka日志存储</h1><h2 id="文件目录布局"><a href="#文件目录布局" class="headerlink" title="文件目录布局"></a>文件目录布局</h2><p>Kafka中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后修改。每个消息在发送的时候会根据分区规则被追加到指定的分区中，分区中的每条消息都会被分配一个唯一的序列号，也就是偏移量</p>
<p><img src="/media/15842482454518.jpg" alt="-w566"></p>
<p>为了防止Log过大，Kafka引入了日志分段的概念，将Log切分为多个LogSegment。Log和LogSegment不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，而每个LogSegment对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件</p>
<p>Log对应了一个命名形式为<topic>-<partition>的文件夹。向Log中追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入操作，在此之前的所有LogSegment都不能写入数据。将最后一个LogSegment称为activeSegment，即表示当前活跃的日志分段。随着消息的不断写入，当activeSegment满足一定条件时，就需要创建新的activeSegment，之后追加的消息写入新的activeSegment</partition></topic></p>
<p>为了便于消息的检索，每个LogSegment中的日志文件都有对应的两个索引文件：偏移量索引文件（以.index为文件后缀）和时间戳索引文件（以.timeindex为文件后缀）。每个LogSegment都有一个基准偏移量baseOffset，用来表示当前LogSegment中第一条消息的offset。偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量命名的，名称固定为20位数字，没有达到的位数则用0填充。比如第一个LogSegment的基准偏移量为0，对应的日志文件为00000000000000000000.log</p>
<p>当Kafka服务第一次启动的时候，默认的根目录下就会创建以下5个文件：<br><code>cleaner-offset-checkpoint    log-start-offset-checkpoint    meta.properties               recovery-point-offset-checkpoint    replication-offset-checkpoint</code></p>
<p>消费者提交的位移是保存在Kafka内部的主题__consumer_offsets中的，初始情况下这个主题并不存在，当第一次有消费者消费信息时会自动创建这个主题</p>
<p><img src="/media/15842484397403.jpg" alt="-w682"></p>
<p>每一个根目录都会包含最基本的4个检查点文件（xxx-checkpoint）和meta.properties。在创建主题的时候，如果当前broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务</p>
<h2 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h2><p>从0.8.x版本开始到现在的2.0.0版本， Kafka的消息格式也经历了3个版本: vO版本、 vl版 本和 v2版本。</p>
<h3 id="V0版本"><a href="#V0版本" class="headerlink" title="V0版本"></a>V0版本</h3><p><img src="/media/15842486953742.jpg" alt="-w586"></p>
<p>每个Record（v0和v1版本）必定对应一个offset和message size。每条消息都有一个offset用来标志它在分区中的偏移量，这个offset是逻辑值，message size表示消息的大小，这两者在一起被称为日志头部（LOG_OVERHEAD），固定为12B。LOG_OVERHEAD和RECORD一起用来描述一条消息。消息集中包含一条或多条消息，消息集不仅是存储于磁盘及在网络上传输的基本形式，而且是Kafka中压缩的基本单位</p>
<ul>
<li>crc32（4B）：crc32校验值。校验范围为magic至value之间</li>
<li>magic（1B）：消息格式版本号，此版本的magic值为0</li>
<li>attributes（1B）：消息的属性。总共占1个字节，低3位表示压缩类型：0表示NONE、1表示GZIP、2表示SNAPPY、3表示LZ4，其余位保留</li>
<li>key length（4B）：表示消息的长度。如果为-1，则表示没有设置key</li>
<li>key：可选，如果没有key则无此字段</li>
<li>value length（4B）：实际消息体的长度。如果为-1，则表示消息为空</li>
<li>value：消息体。可以为空，比如墓碑消息</li>
</ul>
<p>v0版本中一个消息的最小长度为crc32+magic+attributes+key length+value length=14B。也就是说，v0版本中一条消息的最小长度为14B，如果小于这个值，那么就是一条破损的消息而不被接收</p>
<h3 id="V1版本"><a href="#V1版本" class="headerlink" title="V1版本"></a>V1版本</h3><p><img src="/media/15842490301193.jpg" alt="-w505"></p>
<p>v1版本比v0版本就多了一个timestamp字段，表示消息的时间戳<br>v1版本的magic字段的值为1。v1版本的attributes字段中的低3位和v0版本的一样，还是表示压缩类型，而第4个为也被利用起来：0表示timestamp类型为CreateTime，而1表示timestamp类型为LogAppendTime，其他位保留。timestamp类型由broker端参数log.message.timestamp.type来配置，默认值为CreateTime，即采用生产者创建消息时的时间戳。如果在创建ProducerRecord时没有显示指定消息的时间戳，那么KafkaProducer也会在发送这条消息前自动添加上</p>
<h3 id="消息压缩"><a href="#消息压缩" class="headerlink" title="消息压缩"></a>消息压缩</h3><p>Kafka实现的压缩方式是将多条消息一起进行压缩。生产者发送到压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩</p>
<p>Kafka日志中使用哪种压缩方式是通过参数compression.type来配置的，默认值为producer，表示保留生产者使用的压缩方式。这个参数还可以设置为gzip、snappy、lz4.如果参数compression.type配置为uncompressed，则表示不压缩<br><img src="/media/15842491423664.jpg" alt="-w533"><br>当消息压缩时是将整个消息集进行压缩作为内层消息，内层消息整体作为外层消息的value<br>压缩后的外层消息中的key为null，value字段中保存的是多条压缩消息，其中Record表示的是从crc32到value的消息格式<br><img src="/media/15842491809480.jpg" alt="-w400"><br>当生产者创建压缩消息的时候，对内部压缩消息设置的offset从0开始为每个内部消息分配offset</p>
<p>其实每个从生产者发出的消息集中的消息offset都是从0开始的，当然这个offset不能直接存储在日志文件中，对offset的转换是在服务端进行的，客户端不需要做这个工作。外层消息保存了内层消息中最后一条消息的绝对位移，绝对位移是相对于整个分区而言的。上图中内层消息中最后一条的offset理应是1030，但被压缩之后就变成了5，而这个1030被赋予给了外层的offset。当消费者消费这个消息集的时候，首先解压缩整个消息集，然后找到内层消息中最后一条消息的inner offset</p>
<p>对于压缩的情形，外层消息的timestamp设置为：</p>
<ul>
<li>如果timestamp类型是CreateTime，那么设置的是内层消息中最大的时间戳</li>
<li>如果timestamp类型是LogAppendTime，那么设置的是Kafka服务器当前的时间戳</li>
</ul>
<p>内层消息的timestamp设置为：</p>
<ul>
<li>如果timestamp类型是CreateTime，那么设置的是生产者创建消息时的时间戳</li>
<li>如果timestamp类型是LogAppendTime，那么所有内层消息的时间戳都会被忽略</li>
</ul>
<h3 id="V2版本"><a href="#V2版本" class="headerlink" title="V2版本"></a>V2版本</h3><p><img src="/media/15842495802579.jpg" alt="-w692"><br>v2版本中消息集称为Record Batch，而不是先前的Message Set，其内部也包含了一条或多条消息。在消息压缩的情形下，Record Batch Header部分（从first offset到records count字段）是不被压缩的，而被压缩的是records字段中的所有内容。生产者客户端中的ProducerBatch对应这里的RecordBatch，而ProducerRecord对应这里的Record<br>Record的内部字段大量采用了Varints（变长整型），这样Kafka可以根据具体的值来确定需要几个字节来保存</p>
<ul>
<li>length：消息总长度</li>
<li>attributes：弃用，但还是在消息格式中占据1B的大小</li>
<li>timestamp delta：时间戳增量。通常一个timestamp需要占用8个字节，如果向这里一样保存与RecordBatch的起始时间戳的差值，则可以进一步节省占有的字节数</li>
<li>offset delta：位移增量。保存与RecordBatch起始位移的差值</li>
<li>headers：Header包含key和value，一个Record里面可以包含0至多个Header</li>
</ul>
<p>v2版本对RecordBatch做了彻底的修改</p>
<ul>
<li>first offset：表示当前RecordBatch的起始位置</li>
<li>length：计算从partition leader epoch字段开始到末尾的长度</li>
<li>partition leader epoch：分区leader纪元，可以看作分区leader的版本号或更新次数</li>
<li>magic：消息格式的版本号，v2版本值为2</li>
<li>attributes：消息属性，这里占用了两个字节。低3位表示压缩格式，同v0和v1；第4位表示时间戳类型；第5位表示此RecordBatch是否处于事务中，0表示非事务，1表示事务。第6位表示是否是控制消息，0表示非控制消息，而1表示是控制消息，控制消息用来支持事务功能</li>
<li>last offset delta：RecordBatch中最后一个Record的offset与first offset的差值</li>
<li>first timestamp：RecordBatch中第一条Record的时间戳</li>
<li>max timestamp：RecordBatch中最大的时间戳</li>
<li>producer id：PID,用来支持幂等和事务</li>
<li>producer epoch：用来支持幂等和事务</li>
<li>first sequence：用来支持幂等和事务</li>
<li>records count：RecordBatch中Record的个数</li>
</ul>
<h2 id="日志索引"><a href="#日志索引" class="headerlink" title="日志索引"></a>日志索引</h2><p>偏移量索引文件用来建立消息偏移量到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳来查找对应的偏移量信息</p>
<p>Kafka中的索引文件以稀疏索引的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由broker端参数log.index.interval.bytes指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值对应地可以增加或缩小索引项的密度</p>
<p>稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中</p>
<p>日志分段文件切分包含以下几个条件，满足其一即可：</p>
<ul>
<li>当前日志分段文件的大小超过了broker端参数log.segment.bytes配置的值，log.segment.bytes参数的默认值为1073741824，即1GB</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天</li>
<li>偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。默认值为10485760，即10MB</li>
<li>追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE（offset-baseOffset&gt;Integer.MAX_VALUE）</li>
</ul>
<p>对非当前活跃的日志分段而言，其对应的索引文件内容已经固定而不需要再写入索引项，所以会被设定为只读。而对当前活跃的日志分段而言，索引文件还会追加更多的索引项，所以被设定为可读写。在索引文件切分的时候，Kafka会关闭当前正在写入的索引文件并置为只读模式，同时以可读写的模式创建新的索引文件，索引文件的大小由broker端参数log.index.size.max.bytes配置。Kafka在创建索引文件的时候会为其预分配log.index.size.max.bytes大小的空间，只有当索引文件进行切分的时候，Kafka才会把该索引文件裁剪到实际的数据大小。也即是说，与当前活跃的日志分段对应的索引文件的大小固定位log.index.size.max.bytes，而其余日志分段对应的索引文件的大小为实际的占用空间</p>
<h3 id="偏移量索引"><a href="#偏移量索引" class="headerlink" title="偏移量索引"></a>偏移量索引</h3><p><img src="/media/15842497275763.jpg" alt=""></p>
<ul>
<li>relativeOffset：相对偏移量，表示消息相对于baseOffset的偏移量，占用4个字节，当前索引文件的文件名即为baseOffset的值</li>
<li>position：物理地址，也就是消息在日志分段文件中对应的物理位置，占用4个字节</li>
</ul>
<p>消息的偏移量占用8个字节，也可以称为绝对偏移量。索引项中没有直接使用绝对偏移量而改为只占用4个字节的相对偏移量（relativeOffset=offset-baseOffset），这样可以减少索引文件占用的空间<br><img src="/media/15842497677950.jpg" alt="-w697"><br>如果要查找偏移量为23的消息，首先通过二分法在偏移量索引文件中找到不大于23的最大索引，即[22,656]，然后从日志分段文件中的物理位置656开始顺序查找偏移量为23的消息<br><img src="/media/15842497819362.jpg" alt=""><br>如果要找到偏移量为268的消息，先定位到baseOffset为251的日志分段，然后计算相对偏移量relativeOffset=268-251=17，之后再在对应的索引文件中找到不大于17的索引项，最后根据索引项中的position定位到具体的日志分段文件位置开始查找目标消息。查找baseOffset为251的日志分段用了跳跃表的结构，Kafka的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段</p>
<p>Kafka强制要求索引文件大小必须是索引项大小的整数倍，对偏移量索引文件而言，必须为8的整数。如果broker端参数log.index.size.max.bytes配置为67，那么Kafka在内部会将其转换为64，即不大于67，并且满足为8的整数倍的条件</p>
<h3 id="时间戳索引"><a href="#时间戳索引" class="headerlink" title="时间戳索引"></a>时间戳索引</h3><p><img src="/media/15842498132402.jpg" alt=""><br>每个索引项占用12个字节，分为两个部分</p>
<ul>
<li>timestamp：当前日志分段最大的时间戳</li>
<li>relativeOffset：时间戳所对应的消息的相对偏移量</li>
</ul>
<p>时间戳索引文件中包含若干个时间戳索引项，每个住家的时间戳索引项中的timestamp必须大于之前追加的索引项的timestamp，否则不予追加。如果broker端参数log.message.timestamp.type设置为LogAppendTime，那么消息的时间戳必定能够保持单调递增；相反，如果是CreateTime类型则无法保证。生产者可以使用类似ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)的方法指定时间戳的值。即使生产者客户端采用自动插入的时间戳也无法保证时间戳能够单调递增，如果两个不同时钟的生产者同时往一个分区中插入消息，那么也会造成当前分区的时间戳乱序</p>
<p>时间戳索引文件大小是索引项大小（12B）的整数倍，如果不满足条件也会进行裁剪。同样假设broker端参数log.index.size.max.bytes配置为67，那么对应于时间戳索引文件，Kafka在内部会将其转换为60</p>
<p><img src="/media/15842498547813.jpg" alt="-w781"><br>如果要查找指定时间戳targetTimeStamp=1526384718288开始的消息，首先是找到不小于指定时间戳的日志分段。这里就无法使用跳跃表来快速定位到相应的日志分段了。<br>1）将targetTimeStamp和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于targetTimeStamp的largestTimeStamp所对应的日志分段。日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间<br>2）找到相应的日志分段之后，在时间戳索引文件中使用二分法查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283,28]，如此便找到了相对偏移量28<br>3）在偏移量索引文件中使用二分法查找到不大于28的最大索引项，即[26,838]<br>4）从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息</p>
<h2 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h2><p>Kafka提供了两种日志清理策略：</p>
<ul>
<li>日志删除：按照一定的保留策略直接删除不符合条件的日志分段</li>
<li>日志压缩：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本</li>
</ul>
<p>可以通过broker端参数log.cleanup.policy来设置日志清理策略，此参数的默认值为delete，即采用日志删除的清理策略。如果要采用日志压缩的清理策略，就需要将log.cleanup.policy设置为compact，并且还需要将log.cleaner.enable（默认值为true）设定为true。通过将log.cleanup.policy设置为”delete,compact”，还可以同时支持日志删除和日志压缩两种策略。日志清理的粒度可以控制到主题级别</p>
<h3 id="日志删除"><a href="#日志删除" class="headerlink" title="日志删除"></a>日志删除</h3><p>在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过broker参数log.retention.check.interval.ms来配置，默认值为300000，即5分钟。当前日志分段的保留策略有3种：基于时间的保留策略、基于日志大小的保留策略和基于日志起始偏移量的保留策略</p>
<h4 id="基于时间"><a href="#基于时间" class="headerlink" title="基于时间"></a>基于时间</h4><p><img src="/media/15842499994189.jpg" alt=""><br>日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）。retentionMs可以通过broker端参数log.retention.hours、log.retention.minutes和log.retention.ms来配置，其中log.retention.ms优先级最高，默认情况下只配置了log.retention.hours参数，其值为168，默认情况下日志分段文件的保留时间为7天</p>
<p>若待删除的日志分段的总数等于该日志文件中所有的日志分段的数量，那么说明所有的日志分段都已过期，但该日志文件中还要有一个日志分段用于接收消息的写入，即必须要保证有一个活跃的日志分段activeSegment，在此种情况下，会先切出一个新的日志分段作为activeSegment，然后执行删除操作</p>
<p>删除日志分段时，首先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上”.deleted”的后缀。最后交由一个以”delete-file”命名的延迟任务来删除这些以”.deleted”为后缀的文件，这个任务的延迟执行时间可以通过file.delete.delay.ms参数来调配，此参数的默认值为60000，即1分钟</p>
<h4 id="基于日志大小"><a href="#基于日志大小" class="headerlink" title="基于日志大小"></a>基于日志大小</h4><p><img src="/media/15842500233532.jpg" alt=""><br>日志删除任务会检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments），retentionSize可以通过broker端参数log.retention.bytes来配置，默认值为-1，表示无穷大。log.retention.bytes配置的是Log中所有日志文件的总大小，而不是单个日志分段的大小。单个日志分段的大小由broker端参数log.segment.bytes来限制，默认值为1073741824，即1GB</p>
<p>基于日志大小的保留策略与基于时间的保留策略类似，首先计算日志文件的总大小size和retentionSize的差值diff，即计算需要删除的日志总大小，然后从日志文件中的第一个日志分段开始进行查找可删除的日志分段的文件集合deletableSegments。查找出deletableSegments之后就执行删除操作，这个删除操作和基于时间的保留策略的删除操作相同</p>
<h4 id="基于日志起始偏移量"><a href="#基于日志起始偏移量" class="headerlink" title="基于日志起始偏移量"></a>基于日志起始偏移量</h4><p><img src="/media/15842500526379.jpg" alt=""><br>一般情况下，日志文件的起始偏移量logStartOffset等于第一个日志分段的baseOffset，但并不是绝对的，logStartOffset的值可以通过DeleteRecordsRequest请求（KafkaAdminClient的deleteRecords()方法、使用kafka-delete-records脚本）、日志的清理和阶段等操作进行修改</p>
<p>基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于等于logStartOffset，若是，则可以删除日志分段。上图中，假设logStartOffset等于25，日志分段1的起始偏移量为0，日志分段2的起始偏移量为11，日志分段3的起始偏移量为23，通过如下动作收集可删除的日志分段的文件集合deletableSegments：</p>
<ul>
<li>A.从头开始遍历每个日志分段，日志分段1的下一个日志分段的起始偏移量为11，小于logStartOffset的大小，将日志分段1加入deletableSegments</li>
<li>B.日志分段2的下一个日志偏移量的起始偏移量为23，也小于logStartOffset的大小，将日志分段2加入deletableSegments</li>
<li>C.日志分段3的下一个日志偏移量在logStartOffset的右侧，故从日志分段3开始的所有日志分段都不会加入deletableSegments</li>
</ul>
<p>收集完可删除的日志分段的文件集合之后的删除操作同基于日志大小的保留策略和基于时间的保留策略相同</p>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>Kafka中的Log Compaction是指在默认的日志删除规则之外提供的一种清理过时数据的方式，会定期将相同key的消息进行合并，只保留最新的value值<br><img src="/media/15842501267485.jpg" alt="-w586"><br>Log Compaction执行前后，日志分段中的每条消息的偏移量和写入时的偏移量保持一致，Log Compaction会生成新的日志分段文件，日志分段中每条消息的物理地址会重新按照新文件来组织。Log Compaction执行过后的偏移量不再是连续的，不过不会影响日志的查询<br><img src="/media/15842501563334.jpg" alt="-w734"><br>每一个日志目录下都有一个名为”cleaner-offset-checkpoint”的文件，这个文件就是清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。通过清理检查点文件可以将Log分成两个部分。如上图所示，通过检查点cleaner checkpoint来划分出一个已经清理过的clean部分和一个还没清理的dirty部分。在日志清理的同时，客户端也可以读取日志中的消息。dirty部分的消息偏移量是逐一递增的，而clean部分的消息偏移量是断续的</p>
<p>firstDirtyOffset表示dirty部分的起始偏移量，而firstUncleanableOffset为dirty部分的截止偏移量，整个dirty部分的偏移量分为为[firstDirtyOffset,firstUncleanableOffset)。为了避免当前活跃的日志分段activeSegment成为热点文件，activeSegment不会参与Log Compaction</p>
<p>Log Compaction是针对key的，所以在使用时应注意每个消息的key值不为null。每个broker会启动log.cleaner.thread（默认值为1）个日志清理线程负责执行清理任务，这些线程会选择污浊率最高的日志文件进行清理。用cleanBytes表示clean部分的日志占用大小，dirtyBytes表示dirty部分的日志占用大小，那么这个日志的污浊率为：dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)dirtyRatio=dirtyBytes/(cleanBytes+dirtyBytes)</p>
<p>为了防止日志比较的频繁清理操作，Kafka还使用了参数log.cleaner.min。cleanable.ratio（默认值为0.5）来限定可进行清理操作的最小污浊率。Kafka中用于保留消费者位移的主题__consumer_offsets使用的就是Log Compaction策略</p>
<h2 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a>磁盘存储</h2><p>Kafka依赖于磁盘来存储和缓存消息。Kafka在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作</p>
<h3 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h3><p>页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变成对内存的访问</p>
<p>当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页是否在页缓存中，如果存在则直接返回数据，从而避免了对物理磁盘的I/O操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性</p>
<p>Kafka中大量使用了页缓存，这是Kafka实现高吞吐的重要因素之一。虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的，但在Kafka中同样提供了同步刷盘及间断性强制刷盘的功能，这些功能可以通过log.flush.interval.message、log.flush.interval.ms等参数来控制。同步刷盘可以提高消息的可靠性，防止由于机器掉电等异常造成处于页缓存而没有及时写入磁盘的消息丢失。消息的可靠性应该由多副本机制来保障，而不是由同步刷盘这种严重影响性能的行为来保障</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>除了消息顺序追加、页缓存等技术，Kafka还使用零拷贝技术来进一步提升性能。零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对于Linux操作系统而言，零拷贝技术依赖于底层的sendfile()方法实现。对应于Java语言，FileChannal.transferTo()方法的底层实现就是sendfile()方法</p>
<p>将静态内容展示给用户这个情形就意味着需要先将静态内容从磁盘中复制出来放到一个内存buf中，然后将这个buf通过套接字传输给用户，进而用户获得静态内容<br><img src="/media/15842502461853.jpg" alt="-w501"><br>A.调用read()时，文件A中的内容被复制到了内核模式下的Read Buffer中<br>B.CPU控制将内核模式数据复制到用户模式下<br>C.调用write()时，将用户模式下的内容复制到内核模式下的Socket Buffer中<br>D.将内核模式下的Socket Buffer的数据复制到网卡设备中传送</p>
<p>采用零拷贝技术，应用程序可以直接请求内核把磁盘中的数据传输给Socket<br><img src="/media/15842502734149.jpg" alt="-w514"><br>零拷贝技术通过DMA（Direct Memory Access）技术将文件内容复制到内核模式下的Read Buffer中。不过没有数据被复制到Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer中。DMA引擎直接将数据从内核模式中传递到网卡设备。零拷贝是针对内核模式而言的，数据在内核模式下实现了零拷贝</p>
<h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p><a href="https://blog.csdn.net/qq_40378034/article/details/90487244" target="_blank" rel="noopener">https://blog.csdn.net/qq_40378034/article/details/90487244</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/kafka/" rel="tag"># kafka</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Kafka/Kakfa主题与分区/" rel="next" title="kafka主题与分区">
                <i class="fa fa-chevron-left"></i> kafka主题与分区
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Kafka/Kafka监控/" rel="prev" title="kafka监控">
                kafka监控 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Liusuifeng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka日志存储"><span class="nav-number">1.</span> <span class="nav-text">Kafka日志存储</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#文件目录布局"><span class="nav-number">1.1.</span> <span class="nav-text">文件目录布局</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#日志格式"><span class="nav-number">1.2.</span> <span class="nav-text">日志格式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#V0版本"><span class="nav-number">1.2.1.</span> <span class="nav-text">V0版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#V1版本"><span class="nav-number">1.2.2.</span> <span class="nav-text">V1版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消息压缩"><span class="nav-number">1.2.3.</span> <span class="nav-text">消息压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#V2版本"><span class="nav-number">1.2.4.</span> <span class="nav-text">V2版本</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#日志索引"><span class="nav-number">1.3.</span> <span class="nav-text">日志索引</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#偏移量索引"><span class="nav-number">1.3.1.</span> <span class="nav-text">偏移量索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#时间戳索引"><span class="nav-number">1.3.2.</span> <span class="nav-text">时间戳索引</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#日志清理"><span class="nav-number">1.4.</span> <span class="nav-text">日志清理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#日志删除"><span class="nav-number">1.4.1.</span> <span class="nav-text">日志删除</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基于时间"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">基于时间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于日志大小"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">基于日志大小</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于日志起始偏移量"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">基于日志起始偏移量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#日志压缩"><span class="nav-number">1.4.2.</span> <span class="nav-text">日志压缩</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#磁盘存储"><span class="nav-number">1.5.</span> <span class="nav-text">磁盘存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#页缓存"><span class="nav-number">1.5.1.</span> <span class="nav-text">页缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#零拷贝"><span class="nav-number">1.5.2.</span> <span class="nav-text">零拷贝</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#资料"><span class="nav-number">1.6.</span> <span class="nav-text">资料</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liusuifeng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
